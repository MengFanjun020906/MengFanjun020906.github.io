<!DOCTYPE html>
<html lang="en">
    <head hexo-theme='https://github.com/volantis-x/hexo-theme-volantis/#5.7.7'>
  <meta name="generator" content="Hexo 5.4.2">
  <meta name="Volantis" content="5.7.7">
  <meta charset="utf-8">
  <!-- SEO相关 -->
  
  <link rel="canonical" href="https://mengfanjun020906.github.io/2025/10/02/stanford cs336 assignment1（上）/"/>
  <!-- 渲染优化 -->
    <meta http-equiv='x-dns-prefetch-control' content='on' />
      <link rel='dns-prefetch' href='https://unpkg.com'>
      <link rel="preconnect" href="https://unpkg.com" crossorigin>
  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta http-equiv="Content-Security-Policy" content=" default-src 'self' https:; block-all-mixed-content; base-uri 'self' https:; form-action 'self' https:; worker-src 'self' https:; connect-src 'self' https: *; img-src 'self' data: https: *; media-src 'self' https: *; font-src 'self' data: https: *; frame-src 'self' https: *; manifest-src 'self' https: *; child-src https:; script-src 'self' https: 'unsafe-inline' *; style-src 'self' https: 'unsafe-inline' *; ">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5">
  <meta content="black-translucent" name="apple-mobile-web-app-status-bar-style">
  <meta content="telephone=no" name="format-detection">
  <!-- import head_begin begin -->
  <!-- import head_begin end -->
  <!-- Custom Files headBegin begin-->
  
  <!-- Custom Files headBegin end-->
    <link rel="shortcut icon" type='image/x-icon' href="https://pic.imgdb.cn/item/640ad0cdf144a01007830622.png">
  <link rel="preload" href="/css/style.css" as="style">
  <link rel="preload" href="https://unpkg.com/volantis-static@0.0.1654736714924/media/fonts/VarelaRound/VarelaRound-Regular.ttf" as="font" type="font/ttf" crossorigin="anonymous">
<link rel="preload" href="https://unpkg.com/volantis-static@0.0.1654736714924/media/fonts/UbuntuMono/UbuntuMono-Regular.ttf" as="font" type="font/ttf" crossorigin="anonymous">

  <!-- feed -->
  <!-- 页面元数据 -->
  <title>Stanford CS336 assignment1（上） - MengFanjun的博客</title>
  <meta name="keywords" content="学习,大模型,null">
  <meta desc name="description" content="20级通信工程大学生的个人博客 - MengFanjun - MengFanjun的博客">
  
<meta property="og:type" content="article">
<meta property="og:title" content="Stanford CS336 assignment1（上）">
<meta property="og:url" content="https://mengfanjun020906.github.io/2025/10/02/Stanford%20CS336%20assignment1%EF%BC%88%E4%B8%8A%EF%BC%89/index.html">
<meta property="og:site_name" content="MengFanjun的博客">
<meta property="og:description" content="源仓库链接：https:&#x2F;&#x2F;github.com&#x2F;stanford-cs336&#x2F;assignment1-basics 介绍 Byte-Pair Encoding (BPE) TokenizerThe Unicode Standard(a) 12&gt;&gt;&gt; chr(0)&amp;#x27;\x00&amp;#x27; (b)_repr_ (字符串表示)：目标是明确和无歧义。它的主要受众是开发者，用于调">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/favicon/android-chrome-192x192.png">
<meta property="article:published_time" content="2025-10-02T03:27:32.000Z">
<meta property="article:modified_time" content="2025-12-12T14:25:39.018Z">
<meta property="article:author" content="MengFanjun">
<meta property="article:tag" content="学习">
<meta property="article:tag" content="大模型">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/favicon/android-chrome-192x192.png">
  <style>
    /* 首屏样式 */
    #safearea {
  display: none;
}
:root {
  --color-site-body: #f4f4f4;
  --color-site-bg: #f4f4f4;
  --color-site-inner: #fff;
  --color-site-footer: #fff;
  --color-card: #fff;
  --color-text: #444;
  --color-block: #f6f6f6;
  --color-inlinecode: #d56d28;
  --color-codeblock: #f6f6f6;
  --color-h1: #444;
  --color-h2: #444;
  --color-h3: #444;
  --color-h4: #444;
  --color-h5: #444;
  --color-h6: #444;
  --color-p: #444;
  --color-list: #666;
  --color-list-hl: #36ac91;
  --color-meta: #888;
  --color-read-bkg: #e0d8c8;
  --color-read-post: #f8f1e2;
  --color-copyright-bkg: #f5f5f5;
}
* {
  box-sizing: border-box;
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  outline: none;
  margin: 0;
  padding: 0;
}
*::-webkit-scrollbar {
  height: 4px;
  width: 4px;
}
*::-webkit-scrollbar-track-piece {
  background: transparent;
}
*::-webkit-scrollbar-thumb {
  background: #44d7b6;
  cursor: pointer;
  border-radius: 2px;
  -webkit-border-radius: 2px;
}
*::-webkit-scrollbar-thumb:hover {
  background: #ff5722;
}
html {
  color: var(--color-text);
  width: 100%;
  height: 100%;
  font-family: UbuntuMono, "Varela Round", "PingFang SC", "Microsoft YaHei", Helvetica, Arial, Menlo, Monaco, monospace, sans-serif;
  font-size: 16px;
}
html >::-webkit-scrollbar {
  height: 4px;
  width: 4px;
}
html >::-webkit-scrollbar-track-piece {
  background: transparent;
}
html >::-webkit-scrollbar-thumb {
  background: #44d7b6;
  cursor: pointer;
  border-radius: 2px;
  -webkit-border-radius: 2px;
}
html >::-webkit-scrollbar-thumb:hover {
  background: #ff5722;
}
body {
  background-color: var(--color-site-body);
  text-rendering: optimizelegibility;
  -webkit-tap-highlight-color: rgba(0,0,0,0);
  line-height: 1.6;
  -webkit-text-size-adjust: 100%;
  -ms-text-size-adjust: 100%;
}
body.modal-active {
  overflow: hidden;
}
@media screen and (max-width: 680px) {
  body.modal-active {
    position: fixed;
    top: 0;
    right: 0;
    bottom: 0;
    left: 0;
  }
}
a {
  color: #2196f3;
  cursor: pointer;
  text-decoration: none;
  transition: all 0.28s ease;
  -webkit-transition: all 0.28s ease;
  -khtml-transition: all 0.28s ease;
  -moz-transition: all 0.28s ease;
  -o-transition: all 0.28s ease;
  -ms-transition: all 0.28s ease;
}
a:hover {
  color: #ff5722;
}
a:active,
a:hover {
  outline: 0;
}
ul,
ol {
  padding-left: 0;
}
ul li,
ol li {
  list-style: none;
}
header {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: block;
}
img {
  border: 0;
  background: none;
  max-width: 100%;
}
svg:not(:root) {
  overflow: hidden;
}
hr {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
  -webkit-box-sizing: content-box;
  -moz-box-sizing: content-box;
  height: 0;
  border: 0;
  border-radius: 1px;
  -webkit-border-radius: 1px;
  border-bottom: 1px solid rgba(68,68,68,0.1);
}
button,
input {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
  text-transform: none;
  -webkit-appearance: button;
  cursor: pointer;
}
@supports (backdrop-filter: blur(20px)) {
  .blur {
    background: rgba(255,255,255,0.9) !important;
    backdrop-filter: saturate(200%) blur(20px);
  }
}
.shadow {
  box-shadow: 0 1px 2px 0px rgba(0,0,0,0.1);
  -webkit-box-shadow: 0 1px 2px 0px rgba(0,0,0,0.1);
}
.shadow.floatable {
  transition: all 0.28s ease;
  -webkit-transition: all 0.28s ease;
  -khtml-transition: all 0.28s ease;
  -moz-transition: all 0.28s ease;
  -o-transition: all 0.28s ease;
  -ms-transition: all 0.28s ease;
}
.shadow.floatable:hover {
  box-shadow: 0 2px 4px 0px rgba(0,0,0,0.1), 0 4px 8px 0px rgba(0,0,0,0.1), 0 8px 16px 0px rgba(0,0,0,0.1);
  -webkit-box-shadow: 0 2px 4px 0px rgba(0,0,0,0.1), 0 4px 8px 0px rgba(0,0,0,0.1), 0 8px 16px 0px rgba(0,0,0,0.1);
}
#l_cover {
  min-height: 64px;
}
.cover-wrapper {
  top: 0;
  left: 0;
  max-width: 100%;
  height: 100vh;
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: -ms-flexbox /* TWEENER - IE 10 */;
  display: -webkit-flex /* NEW - Chrome */;
  display: flex /* NEW, Spec - Opera 12.1, Firefox 20+ */;
  display: flex;
  flex-wrap: nowrap;
  -webkit-flex-wrap: nowrap;
  -khtml-flex-wrap: nowrap;
  -moz-flex-wrap: nowrap;
  -o-flex-wrap: nowrap;
  -ms-flex-wrap: nowrap;
  -webkit-box-direction: normal;
  -moz-box-direction: normal;
  -webkit-box-orient: vertical;
  -moz-box-orient: vertical;
  -webkit-flex-direction: column;
  -ms-flex-direction: column;
  flex-direction: column;
  align-items: center;
  align-self: center;
  align-content: center;
  color: var(--color-site-inner);
  padding: 0 16px;
  user-select: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  position: relative;
  overflow: hidden;
  margin-bottom: -100px;
}
.cover-wrapper .cover-body {
  z-index: 1;
  position: relative;
  width: 100%;
  height: 100%;
}
.cover-wrapper#full {
  height: calc(100vh + 100px);
  padding-bottom: 100px;
}
.cover-wrapper#half {
  max-height: 640px;
  min-height: 400px;
  height: calc(36vh - 64px + 200px);
}
.cover-wrapper #scroll-down {
  width: 100%;
  height: 64px;
  position: absolute;
  bottom: 100px;
  text-align: center;
  cursor: pointer;
}
.cover-wrapper #scroll-down .scroll-down-effects {
  color: #fff;
  font-size: 24px;
  line-height: 64px;
  position: absolute;
  width: 24px;
  left: calc(50% - 12px);
  text-shadow: 0 1px 2px rgba(0,0,0,0.1);
  animation: scroll-down-effect 1.5s infinite;
  -webkit-animation: scroll-down-effect 1.5s infinite;
  -khtml-animation: scroll-down-effect 1.5s infinite;
  -moz-animation: scroll-down-effect 1.5s infinite;
  -o-animation: scroll-down-effect 1.5s infinite;
  -ms-animation: scroll-down-effect 1.5s infinite;
}
@-moz-keyframes scroll-down-effect {
  0% {
    top: 0;
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
  50% {
    top: -16px;
    opacity: 0.4;
    -webkit-opacity: 0.4;
    -moz-opacity: 0.4;
  }
  100% {
    top: 0;
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
}
@-webkit-keyframes scroll-down-effect {
  0% {
    top: 0;
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
  50% {
    top: -16px;
    opacity: 0.4;
    -webkit-opacity: 0.4;
    -moz-opacity: 0.4;
  }
  100% {
    top: 0;
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
}
@-o-keyframes scroll-down-effect {
  0% {
    top: 0;
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
  50% {
    top: -16px;
    opacity: 0.4;
    -webkit-opacity: 0.4;
    -moz-opacity: 0.4;
  }
  100% {
    top: 0;
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
}
@keyframes scroll-down-effect {
  0% {
    top: 0;
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
  50% {
    top: -16px;
    opacity: 0.4;
    -webkit-opacity: 0.4;
    -moz-opacity: 0.4;
  }
  100% {
    top: 0;
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
}
.cover-wrapper .cover-body {
  margin-top: 64px;
  margin-bottom: 100px;
}
.cover-wrapper .cover-body,
.cover-wrapper .cover-body .top,
.cover-wrapper .cover-body .bottom {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: -ms-flexbox /* TWEENER - IE 10 */;
  display: -webkit-flex /* NEW - Chrome */;
  display: flex /* NEW, Spec - Opera 12.1, Firefox 20+ */;
  display: flex;
  -webkit-box-direction: normal;
  -moz-box-direction: normal;
  -webkit-box-orient: vertical;
  -moz-box-orient: vertical;
  -webkit-flex-direction: column;
  -ms-flex-direction: column;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  -webkit-justify-content: center;
  -khtml-justify-content: center;
  -moz-justify-content: center;
  -o-justify-content: center;
  -ms-justify-content: center;
  max-width: 100%;
}
.cover-wrapper .cover-body .bottom {
  margin-top: 32px;
}
.cover-wrapper .cover-body .title {
  font-family: "Varela Round", "PingFang SC", "Microsoft YaHei", Helvetica, Arial, Helvetica, monospace;
  font-size: 3.125rem;
  line-height: 1.2;
  text-shadow: 0 1px 2px rgba(0,0,0,0.1);
}
.cover-wrapper .cover-body .subtitle {
  font-size: 20px;
}
.cover-wrapper .cover-body .logo {
  max-height: 120px;
  max-width: calc(100% - 4 * 16px);
}
@media screen and (min-height: 1024px) {
  .cover-wrapper .cover-body .title {
    font-size: 3rem;
  }
  .cover-wrapper .cover-body .subtitle {
    font-size: 1.05rem;
  }
  .cover-wrapper .cover-body .logo {
    max-height: 150px;
  }
}
.cover-wrapper .cover-body .m_search {
  position: relative;
  max-width: calc(100% - 16px);
  width: 320px;
  vertical-align: middle;
}
.cover-wrapper .cover-body .m_search .form {
  position: relative;
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: block;
  width: 100%;
}
.cover-wrapper .cover-body .m_search .icon,
.cover-wrapper .cover-body .m_search .input {
  transition: all 0.28s ease;
  -webkit-transition: all 0.28s ease;
  -khtml-transition: all 0.28s ease;
  -moz-transition: all 0.28s ease;
  -o-transition: all 0.28s ease;
  -ms-transition: all 0.28s ease;
}
.cover-wrapper .cover-body .m_search .icon {
  position: absolute;
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: block;
  line-height: 2.5rem;
  width: 32px;
  top: 0;
  left: 5px;
  color: rgba(68,68,68,0.75);
}
.cover-wrapper .cover-body .m_search .input {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: block;
  height: 2.5rem;
  width: 100%;
  box-shadow: none;
  -webkit-box-shadow: none;
  box-sizing: border-box;
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  font-size: 0.875rem;
  -webkit-appearance: none;
  padding-left: 36px;
  border-radius: 1.4rem;
  -webkit-border-radius: 1.4rem;
  background: rgba(255,255,255,0.6);
  backdrop-filter: blur(10px);
  border: none;
  color: var(--color-text);
}
@media screen and (max-width: 500px) {
  .cover-wrapper .cover-body .m_search .input {
    padding-left: 36px;
  }
}
.cover-wrapper .cover-body .m_search .input:hover {
  background: rgba(255,255,255,0.8);
}
.cover-wrapper .cover-body .m_search .input:focus {
  background: #fff;
}
.cover-wrapper .list-h {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: -ms-flexbox /* TWEENER - IE 10 */;
  display: -webkit-flex /* NEW - Chrome */;
  display: flex /* NEW, Spec - Opera 12.1, Firefox 20+ */;
  display: flex;
  -webkit-box-direction: normal;
  -moz-box-direction: normal;
  -webkit-box-orient: horizontal;
  -moz-box-orient: horizontal;
  -webkit-flex-direction: row;
  -ms-flex-direction: row;
  flex-direction: row;
  flex-wrap: wrap;
  -webkit-flex-wrap: wrap;
  -khtml-flex-wrap: wrap;
  -moz-flex-wrap: wrap;
  -o-flex-wrap: wrap;
  -ms-flex-wrap: wrap;
  align-items: stretch;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  user-select: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
}
.cover-wrapper .list-h a {
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  -webkit-flex: 1 0;
  -ms-flex: 1 0;
  flex: 1 0;
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: -ms-flexbox /* TWEENER - IE 10 */;
  display: -webkit-flex /* NEW - Chrome */;
  display: flex /* NEW, Spec - Opera 12.1, Firefox 20+ */;
  display: flex;
  font-weight: 600;
}
.cover-wrapper .list-h a img {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: block;
  border-radius: 2px;
  -webkit-border-radius: 2px;
  margin: 4px;
  min-width: 40px;
  max-width: 44px;
}
@media screen and (max-width: 768px) {
  .cover-wrapper .list-h a img {
    min-width: 36px;
    max-width: 40px;
  }
}
@media screen and (max-width: 500px) {
  .cover-wrapper .list-h a img {
    margin: 2px 4px;
    min-width: 32px;
    max-width: 36px;
  }
}
@media screen and (max-width: 375px) {
  .cover-wrapper .list-h a img {
    min-width: 28px;
    max-width: 32px;
  }
}
.cover-wrapper {
  max-width: 100%;
}
.cover-wrapper.search .bottom .menu {
  margin-top: 16px;
}
.cover-wrapper.search .bottom .menu .list-h a {
  white-space: nowrap;
  -webkit-box-direction: normal;
  -moz-box-direction: normal;
  -webkit-box-orient: horizontal;
  -moz-box-orient: horizontal;
  -webkit-flex-direction: row;
  -ms-flex-direction: row;
  flex-direction: row;
  align-items: baseline;
  padding: 2px;
  margin: 4px;
  color: var(--color-site-inner);
  opacity: 0.75;
  -webkit-opacity: 0.75;
  -moz-opacity: 0.75;
  text-shadow: 0 1px 2px rgba(0,0,0,0.05);
  border-bottom: 2px solid transparent;
}
.cover-wrapper.search .bottom .menu .list-h a i {
  margin-right: 4px;
}
.cover-wrapper.search .bottom .menu .list-h a p {
  font-size: 0.9375rem;
}
.cover-wrapper.search .bottom .menu .list-h a:hover,
.cover-wrapper.search .bottom .menu .list-h a.active,
.cover-wrapper.search .bottom .menu .list-h a:active {
  opacity: 1;
  -webkit-opacity: 1;
  -moz-opacity: 1;
  border-bottom: 2px solid var(--color-site-inner);
}
.cover-wrapper #parallax-window {
  position: absolute;
  width: 100%;
  height: 100%;
  background: transparent;
}
.parallax-mirror {
  animation-delay: 0s;
  animation-duration: 0.5s;
  animation-fill-mode: forwards;
  animation-timing-function: ease-out;
  animation-name: fadeIn;
}
@-moz-keyframes fadeIn {
  0% {
    opacity: 0;
    -webkit-opacity: 0;
    -moz-opacity: 0;
    filter: blur(12px);
  }
  100% {
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  0% {
    opacity: 0;
    -webkit-opacity: 0;
    -moz-opacity: 0;
    filter: blur(12px);
  }
  100% {
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
}
@-o-keyframes fadeIn {
  0% {
    opacity: 0;
    -webkit-opacity: 0;
    -moz-opacity: 0;
    filter: blur(12px);
  }
  100% {
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
}
@keyframes fadeIn {
  0% {
    opacity: 0;
    -webkit-opacity: 0;
    -moz-opacity: 0;
    filter: blur(12px);
  }
  100% {
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
}
@font-face {
  font-family: 'UbuntuMono';
  src: url("https://unpkg.com/volantis-static@0.0.1654736714924/media/fonts/UbuntuMono/UbuntuMono-Regular.ttf");
  font-weight: 'normal';
  font-style: 'normal';
  font-display: swap;
}
@font-face {
  font-family: 'Varela Round';
  src: url("https://unpkg.com/volantis-static@0.0.1654736714924/media/fonts/VarelaRound/VarelaRound-Regular.ttf");
  font-weight: 'normal';
  font-style: 'normal';
  font-display: swap;
}
.l_header {
  position: fixed;
  z-index: 1000;
  top: 0;
  width: 100%;
  height: 64px;
  background: var(--color-card);
  box-shadow: 0 1px 2px 0px rgba(0,0,0,0.1);
  -webkit-box-shadow: 0 1px 2px 0px rgba(0,0,0,0.1);
}
.l_header.auto {
  transition: opacity 0.4s ease;
  -webkit-transition: opacity 0.4s ease;
  -khtml-transition: opacity 0.4s ease;
  -moz-transition: opacity 0.4s ease;
  -o-transition: opacity 0.4s ease;
  -ms-transition: opacity 0.4s ease;
  visibility: hidden;
}
.l_header.auto.show {
  opacity: 1 !important;
  -webkit-opacity: 1 !important;
  -moz-opacity: 1 !important;
  visibility: visible;
}
.l_header .container {
  margin-left: 16px;
  margin-right: 16px;
}
.l_header #wrapper {
  height: 100%;
  user-select: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
}
.l_header #wrapper .nav-main,
.l_header #wrapper .nav-sub {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: -ms-flexbox /* TWEENER - IE 10 */;
  display: -webkit-flex /* NEW - Chrome */;
  display: flex /* NEW, Spec - Opera 12.1, Firefox 20+ */;
  display: flex;
  flex-wrap: nowrap;
  -webkit-flex-wrap: nowrap;
  -khtml-flex-wrap: nowrap;
  -moz-flex-wrap: nowrap;
  -o-flex-wrap: nowrap;
  -ms-flex-wrap: nowrap;
  justify-content: space-between;
  -webkit-justify-content: space-between;
  -khtml-justify-content: space-between;
  -moz-justify-content: space-between;
  -o-justify-content: space-between;
  -ms-justify-content: space-between;
  align-items: center;
}
.l_header #wrapper .nav-main {
  transition: all 0.28s ease;
  -webkit-transition: all 0.28s ease;
  -khtml-transition: all 0.28s ease;
  -moz-transition: all 0.28s ease;
  -o-transition: all 0.28s ease;
  -ms-transition: all 0.28s ease;
}
.l_header #wrapper.sub .nav-main {
  transform: translateY(-64px);
  -webkit-transform: translateY(-64px);
  -khtml-transform: translateY(-64px);
  -moz-transform: translateY(-64px);
  -o-transform: translateY(-64px);
  -ms-transform: translateY(-64px);
}
.l_header #wrapper .nav-sub {
  transition: all 0.28s ease;
  -webkit-transition: all 0.28s ease;
  -khtml-transition: all 0.28s ease;
  -moz-transition: all 0.28s ease;
  -o-transition: all 0.28s ease;
  -ms-transition: all 0.28s ease;
  opacity: 0;
  -webkit-opacity: 0;
  -moz-opacity: 0;
  height: 64px;
  width: calc(100% - 2 * 16px);
  position: absolute;
}
.l_header #wrapper .nav-sub ::-webkit-scrollbar {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: none;
}
@media screen and (min-width: 2048px) {
  .l_header #wrapper .nav-sub {
    max-width: 55vw;
    margin: auto;
  }
}
.l_header #wrapper.sub .nav-sub {
  opacity: 1;
  -webkit-opacity: 1;
  -moz-opacity: 1;
}
.l_header #wrapper .title {
  position: relative;
  color: var(--color-text);
  padding-left: 24px;
  max-height: 64px;
}
.l_header #wrapper .nav-main .title {
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  flex-shrink: 0;
  line-height: 64px;
  padding: 0 24px;
  font-size: 1.25rem;
  font-family: "Varela Round", "PingFang SC", "Microsoft YaHei", Helvetica, Arial, Helvetica, monospace;
}
.l_header #wrapper .nav-main .title img {
  height: 64px;
}
.l_header .nav-sub {
  max-width: 1080px;
  margin: auto;
}
.l_header .nav-sub .title {
  font-weight: bold;
  font-family: UbuntuMono, "Varela Round", "PingFang SC", "Microsoft YaHei", Helvetica, Arial, Menlo, Monaco, monospace, sans-serif;
  line-height: 1.2;
  max-height: 64px;
  white-space: normal;
  flex-shrink: 1;
}
.l_header .switcher {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: none;
  line-height: 64px;
  align-items: center;
}
.l_header .switcher .s-toc {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: none;
}
@media screen and (max-width: 768px) {
  .l_header .switcher .s-toc {
    display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
    display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
    display: -ms-flexbox /* TWEENER - IE 10 */;
    display: -webkit-flex /* NEW - Chrome */;
    display: flex /* NEW, Spec - Opera 12.1, Firefox 20+ */;
    display: flex;
  }
}
.l_header .switcher >li {
  height: 48px;
  transition: all 0.28s ease;
  -webkit-transition: all 0.28s ease;
  -khtml-transition: all 0.28s ease;
  -moz-transition: all 0.28s ease;
  -o-transition: all 0.28s ease;
  -ms-transition: all 0.28s ease;
  margin: 2px;
}
@media screen and (max-width: 500px) {
  .l_header .switcher >li {
    margin: 0 1px;
    height: 48px;
  }
}
.l_header .switcher >li >a {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: -ms-flexbox /* TWEENER - IE 10 */;
  display: -webkit-flex /* NEW - Chrome */;
  display: flex /* NEW, Spec - Opera 12.1, Firefox 20+ */;
  display: flex;
  justify-content: center;
  -webkit-justify-content: center;
  -khtml-justify-content: center;
  -moz-justify-content: center;
  -o-justify-content: center;
  -ms-justify-content: center;
  align-items: center;
  width: 48px;
  height: 48px;
  padding: 0.85em 1.1em;
  border-radius: 100px;
  -webkit-border-radius: 100px;
  border: none;
  transition: all 0.28s ease;
  -webkit-transition: all 0.28s ease;
  -khtml-transition: all 0.28s ease;
  -moz-transition: all 0.28s ease;
  -o-transition: all 0.28s ease;
  -ms-transition: all 0.28s ease;
  color: #44d7b6;
}
.l_header .switcher >li >a:hover {
  border: none;
}
.l_header .switcher >li >a.active,
.l_header .switcher >li >a:active {
  border: none;
  background: var(--color-site-bg);
}
@media screen and (max-width: 500px) {
  .l_header .switcher >li >a {
    width: 36px;
    height: 48px;
  }
}
.l_header .nav-sub .switcher {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: -ms-flexbox /* TWEENER - IE 10 */;
  display: -webkit-flex /* NEW - Chrome */;
  display: flex /* NEW, Spec - Opera 12.1, Firefox 20+ */;
  display: flex;
}
.l_header .m_search {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: -ms-flexbox /* TWEENER - IE 10 */;
  display: -webkit-flex /* NEW - Chrome */;
  display: flex /* NEW, Spec - Opera 12.1, Firefox 20+ */;
  display: flex;
  height: 64px;
  width: 240px;
  transition: all 0.28s ease;
  -webkit-transition: all 0.28s ease;
  -khtml-transition: all 0.28s ease;
  -moz-transition: all 0.28s ease;
  -o-transition: all 0.28s ease;
  -ms-transition: all 0.28s ease;
}
@media screen and (max-width: 1024px) {
  .l_header .m_search {
    width: 44px;
    min-width: 44px;
  }
  .l_header .m_search input::placeholder {
    opacity: 0;
    -webkit-opacity: 0;
    -moz-opacity: 0;
  }
  .l_header .m_search:hover {
    width: 240px;
  }
  .l_header .m_search:hover input::placeholder {
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
}
@media screen and (min-width: 500px) {
  .l_header .m_search:hover .input {
    width: 100%;
  }
  .l_header .m_search:hover .input::placeholder {
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
}
@media screen and (max-width: 500px) {
  .l_header .m_search {
    min-width: 0;
  }
  .l_header .m_search input::placeholder {
    opacity: 1;
    -webkit-opacity: 1;
    -moz-opacity: 1;
  }
}
.l_header .m_search .form {
  position: relative;
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: -ms-flexbox /* TWEENER - IE 10 */;
  display: -webkit-flex /* NEW - Chrome */;
  display: flex /* NEW, Spec - Opera 12.1, Firefox 20+ */;
  display: flex;
  width: 100%;
  align-items: center;
}
.l_header .m_search .icon {
  position: absolute;
  width: 36px;
  left: 5px;
  color: var(--color-meta);
}
@media screen and (max-width: 500px) {
  .l_header .m_search .icon {
    display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
    display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
    display: none;
  }
}
.l_header .m_search .input {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: block;
  padding-top: 8px;
  padding-bottom: 8px;
  line-height: 1.3;
  width: 100%;
  color: var(--color-text);
  background: #fafafa;
  box-shadow: none;
  -webkit-box-shadow: none;
  box-sizing: border-box;
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  padding-left: 40px;
  font-size: 0.875rem;
  border-radius: 8px;
  -webkit-border-radius: 8px;
  border: none;
  transition: all 0.28s ease;
  -webkit-transition: all 0.28s ease;
  -khtml-transition: all 0.28s ease;
  -moz-transition: all 0.28s ease;
  -o-transition: all 0.28s ease;
  -ms-transition: all 0.28s ease;
}
@media screen and (min-width: 500px) {
  .l_header .m_search .input:focus {
    box-shadow: 0 4px 8px 0px rgba(0,0,0,0.1);
    -webkit-box-shadow: 0 4px 8px 0px rgba(0,0,0,0.1);
  }
}
@media screen and (max-width: 500px) {
  .l_header .m_search .input {
    background: var(--color-block);
    padding-left: 8px;
    border: none;
  }
  .l_header .m_search .input:hover,
  .l_header .m_search .input:focus {
    border: none;
  }
}
@media (max-width: 500px) {
  .l_header .m_search {
    left: 0;
    width: 0;
    overflow: hidden;
    position: absolute;
    background: #fff;
    transition: all 0.28s ease;
    -webkit-transition: all 0.28s ease;
    -khtml-transition: all 0.28s ease;
    -moz-transition: all 0.28s ease;
    -o-transition: all 0.28s ease;
    -ms-transition: all 0.28s ease;
  }
  .l_header .m_search .input {
    border-radius: 32px;
    -webkit-border-radius: 32px;
    margin-left: 16px;
    padding-left: 16px;
  }
  .l_header.z_search-open .m_search {
    width: 100%;
  }
  .l_header.z_search-open .m_search .input {
    width: calc(100% - 120px);
  }
}
ul.m-pc >li>a {
  color: inherit;
  border-bottom: 2px solid transparent;
}
ul.m-pc >li>a:active,
ul.m-pc >li>a.active {
  border-bottom: 2px solid #44d7b6;
}
ul.m-pc li:hover >ul.list-v,
ul.list-v li:hover >ul.list-v {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: block;
}
ul.nav-list-h {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: -ms-flexbox /* TWEENER - IE 10 */;
  display: -webkit-flex /* NEW - Chrome */;
  display: flex /* NEW, Spec - Opera 12.1, Firefox 20+ */;
  display: flex;
  align-items: stretch;
}
ul.nav-list-h>li {
  position: relative;
  justify-content: center;
  -webkit-justify-content: center;
  -khtml-justify-content: center;
  -moz-justify-content: center;
  -o-justify-content: center;
  -ms-justify-content: center;
  height: 100%;
  line-height: 2.4;
  border-radius: 4px;
  -webkit-border-radius: 4px;
}
ul.nav-list-h>li >a {
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  font-weight: 600;
}
ul.list-v {
  z-index: 1;
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: none;
  position: absolute;
  background: var(--color-card);
  box-shadow: 0 2px 4px 0px rgba(0,0,0,0.08), 0 4px 8px 0px rgba(0,0,0,0.08), 0 8px 16px 0px rgba(0,0,0,0.08);
  -webkit-box-shadow: 0 2px 4px 0px rgba(0,0,0,0.08), 0 4px 8px 0px rgba(0,0,0,0.08), 0 8px 16px 0px rgba(0,0,0,0.08);
  margin-top: -6px;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  padding: 8px 0;
}
ul.list-v.show {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: block;
}
ul.list-v hr {
  margin-top: 8px;
  margin-bottom: 8px;
}
ul.list-v >li {
  white-space: nowrap;
  word-break: keep-all;
}
ul.list-v >li.header {
  font-size: 0.78125rem;
  font-weight: bold;
  line-height: 2em;
  color: var(--color-meta);
  margin: 8px 16px 4px;
}
ul.list-v >li.header i {
  margin-right: 8px;
}
ul.list-v >li ul {
  margin-left: 0;
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: none;
  margin-top: -40px;
}
ul.list-v .aplayer-container {
  min-height: 64px;
  padding: 6px 16px;
}
ul.list-v >li>a {
  transition: all 0.28s ease;
  -webkit-transition: all 0.28s ease;
  -khtml-transition: all 0.28s ease;
  -moz-transition: all 0.28s ease;
  -o-transition: all 0.28s ease;
  -ms-transition: all 0.28s ease;
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: block;
  color: var(--color-list);
  font-size: 0.875rem;
  font-weight: bold;
  line-height: 36px;
  padding: 0 20px 0 16px;
  text-overflow: ellipsis;
  margin: 0 4px;
  border-radius: 4px;
  -webkit-border-radius: 4px;
}
@media screen and (max-width: 1024px) {
  ul.list-v >li>a {
    line-height: 40px;
  }
}
ul.list-v >li>a >i {
  margin-right: 8px;
}
ul.list-v >li>a:active,
ul.list-v >li>a.active {
  color: var(--color-list-hl);
}
ul.list-v >li>a:hover {
  color: var(--color-list-hl);
  background: var(--color-site-bg);
}
.l_header .menu >ul>li>a {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: block;
  padding: 0 8px;
}
.l_header .menu >ul>li>a >i {
  margin-right: 4px;
}
.l_header ul.nav-list-h>li {
  color: var(--color-list);
  line-height: 64px;
}
.l_header ul.nav-list-h>li >a {
  max-height: 64px;
  overflow: hidden;
  color: inherit;
}
.l_header ul.nav-list-h>li >a:active,
.l_header ul.nav-list-h>li >a.active {
  color: #44d7b6;
}
.l_header ul.nav-list-h>li:hover>a {
  color: var(--color-list-hl);
}
.l_header ul.nav-list-h>li i.music {
  animation: rotate-effect 1.5s linear infinite;
  -webkit-animation: rotate-effect 1.5s linear infinite;
  -khtml-animation: rotate-effect 1.5s linear infinite;
  -moz-animation: rotate-effect 1.5s linear infinite;
  -o-animation: rotate-effect 1.5s linear infinite;
  -ms-animation: rotate-effect 1.5s linear infinite;
}
@-moz-keyframes rotate-effect {
  0% {
    transform: rotate(0);
    -webkit-transform: rotate(0);
    -khtml-transform: rotate(0);
    -moz-transform: rotate(0);
    -o-transform: rotate(0);
    -ms-transform: rotate(0);
  }
  25% {
    transform: rotate(90deg);
    -webkit-transform: rotate(90deg);
    -khtml-transform: rotate(90deg);
    -moz-transform: rotate(90deg);
    -o-transform: rotate(90deg);
    -ms-transform: rotate(90deg);
  }
  50% {
    transform: rotate(180deg);
    -webkit-transform: rotate(180deg);
    -khtml-transform: rotate(180deg);
    -moz-transform: rotate(180deg);
    -o-transform: rotate(180deg);
    -ms-transform: rotate(180deg);
  }
  75% {
    transform: rotate(270deg);
    -webkit-transform: rotate(270deg);
    -khtml-transform: rotate(270deg);
    -moz-transform: rotate(270deg);
    -o-transform: rotate(270deg);
    -ms-transform: rotate(270deg);
  }
  100% {
    transform: rotate(360deg);
    -webkit-transform: rotate(360deg);
    -khtml-transform: rotate(360deg);
    -moz-transform: rotate(360deg);
    -o-transform: rotate(360deg);
    -ms-transform: rotate(360deg);
  }
}
@-webkit-keyframes rotate-effect {
  0% {
    transform: rotate(0);
    -webkit-transform: rotate(0);
    -khtml-transform: rotate(0);
    -moz-transform: rotate(0);
    -o-transform: rotate(0);
    -ms-transform: rotate(0);
  }
  25% {
    transform: rotate(90deg);
    -webkit-transform: rotate(90deg);
    -khtml-transform: rotate(90deg);
    -moz-transform: rotate(90deg);
    -o-transform: rotate(90deg);
    -ms-transform: rotate(90deg);
  }
  50% {
    transform: rotate(180deg);
    -webkit-transform: rotate(180deg);
    -khtml-transform: rotate(180deg);
    -moz-transform: rotate(180deg);
    -o-transform: rotate(180deg);
    -ms-transform: rotate(180deg);
  }
  75% {
    transform: rotate(270deg);
    -webkit-transform: rotate(270deg);
    -khtml-transform: rotate(270deg);
    -moz-transform: rotate(270deg);
    -o-transform: rotate(270deg);
    -ms-transform: rotate(270deg);
  }
  100% {
    transform: rotate(360deg);
    -webkit-transform: rotate(360deg);
    -khtml-transform: rotate(360deg);
    -moz-transform: rotate(360deg);
    -o-transform: rotate(360deg);
    -ms-transform: rotate(360deg);
  }
}
@-o-keyframes rotate-effect {
  0% {
    transform: rotate(0);
    -webkit-transform: rotate(0);
    -khtml-transform: rotate(0);
    -moz-transform: rotate(0);
    -o-transform: rotate(0);
    -ms-transform: rotate(0);
  }
  25% {
    transform: rotate(90deg);
    -webkit-transform: rotate(90deg);
    -khtml-transform: rotate(90deg);
    -moz-transform: rotate(90deg);
    -o-transform: rotate(90deg);
    -ms-transform: rotate(90deg);
  }
  50% {
    transform: rotate(180deg);
    -webkit-transform: rotate(180deg);
    -khtml-transform: rotate(180deg);
    -moz-transform: rotate(180deg);
    -o-transform: rotate(180deg);
    -ms-transform: rotate(180deg);
  }
  75% {
    transform: rotate(270deg);
    -webkit-transform: rotate(270deg);
    -khtml-transform: rotate(270deg);
    -moz-transform: rotate(270deg);
    -o-transform: rotate(270deg);
    -ms-transform: rotate(270deg);
  }
  100% {
    transform: rotate(360deg);
    -webkit-transform: rotate(360deg);
    -khtml-transform: rotate(360deg);
    -moz-transform: rotate(360deg);
    -o-transform: rotate(360deg);
    -ms-transform: rotate(360deg);
  }
}
@keyframes rotate-effect {
  0% {
    transform: rotate(0);
    -webkit-transform: rotate(0);
    -khtml-transform: rotate(0);
    -moz-transform: rotate(0);
    -o-transform: rotate(0);
    -ms-transform: rotate(0);
  }
  25% {
    transform: rotate(90deg);
    -webkit-transform: rotate(90deg);
    -khtml-transform: rotate(90deg);
    -moz-transform: rotate(90deg);
    -o-transform: rotate(90deg);
    -ms-transform: rotate(90deg);
  }
  50% {
    transform: rotate(180deg);
    -webkit-transform: rotate(180deg);
    -khtml-transform: rotate(180deg);
    -moz-transform: rotate(180deg);
    -o-transform: rotate(180deg);
    -ms-transform: rotate(180deg);
  }
  75% {
    transform: rotate(270deg);
    -webkit-transform: rotate(270deg);
    -khtml-transform: rotate(270deg);
    -moz-transform: rotate(270deg);
    -o-transform: rotate(270deg);
    -ms-transform: rotate(270deg);
  }
  100% {
    transform: rotate(360deg);
    -webkit-transform: rotate(360deg);
    -khtml-transform: rotate(360deg);
    -moz-transform: rotate(360deg);
    -o-transform: rotate(360deg);
    -ms-transform: rotate(360deg);
  }
}
.menu-phone li ul.list-v {
  right: calc(100% - 0.5 * 16px);
}
.menu-phone li ul.list-v ul {
  right: calc(100% - 0.5 * 16px);
}
#wrapper {
  max-width: 1080px;
  margin: auto;
}
@media screen and (min-width: 2048px) {
  #wrapper {
    max-width: 55vw;
  }
}
#wrapper .menu {
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  -webkit-flex: 1 1;
  -ms-flex: 1 1;
  flex: 1 1;
  margin: 0 16px 0 0;
}
#wrapper .menu .list-v ul {
  left: calc(100% - 0.5 * 16px);
}
.menu-phone {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: none;
  margin-top: 16px;
  right: 8px;
  transition: all 0.28s ease;
  -webkit-transition: all 0.28s ease;
  -khtml-transition: all 0.28s ease;
  -moz-transition: all 0.28s ease;
  -o-transition: all 0.28s ease;
  -ms-transition: all 0.28s ease;
}
.menu-phone ul {
  right: calc(100% - 0.5 * 16px);
}
@media screen and (max-width: 500px) {
  .menu-phone {
    display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
    display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
    display: block;
  }
}
.l_header {
  max-width: 65vw;
  left: calc((100% - 65vw) * 0.5);
  border-bottom-left-radius: 8px;
  border-bottom-right-radius: 8px;
}
@media screen and (max-width: 2048px) {
  .l_header {
    max-width: 1112px;
    left: calc((100% - 1112px) * 0.5);
  }
}
@media screen and (max-width: 1112px) {
  .l_header {
    left: 0;
    border-radius: 0;
    -webkit-border-radius: 0;
    max-width: 100%;
  }
}
@media screen and (max-width: 500px) {
  .l_header .container {
    margin-left: 0;
    margin-right: 0;
  }
  .l_header #wrapper .nav-main .title {
    padding-left: 16px;
    padding-right: 16px;
  }
  .l_header #wrapper .nav-sub {
    width: 100%;
  }
  .l_header #wrapper .nav-sub .title {
    overflow-y: scroll;
    margin-top: 2px;
    padding: 8px 16px;
  }
  .l_header #wrapper .switcher {
    display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
    display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
    display: -ms-flexbox /* TWEENER - IE 10 */;
    display: -webkit-flex /* NEW - Chrome */;
    display: flex /* NEW, Spec - Opera 12.1, Firefox 20+ */;
    display: flex;
    margin-right: 8px;
  }
  .l_header .menu {
    display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
    display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
    display: none;
  }
}
@media screen and (max-width: 500px) {
  .list-v li {
    max-width: 270px;
  }
}
#u-search {
  display: -webkit-box /* OLD - iOS 6-, Safari 3.1-6 */;
  display: -moz-box /* OLD - Firefox 19- (buggy but mostly works) */;
  display: none;
  position: fixed;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  padding: 60px 20px;
  z-index: 1001;
}
@media screen and (max-width: 680px) {
  #u-search {
    padding: 0px;
  }
}

  </style>
  <link rel="stylesheet" href="/css/style.css" media="print" onload="this.media='all';this.onload=null">
  <noscript><link rel="stylesheet" href="/css/style.css"></noscript>
  
<script>
if (/*@cc_on!@*/false || (!!window.MSInputMethodContext && !!document.documentMode))
    document.write(
	'<style>'+
		'html{'+
			'overflow-x: hidden !important;'+
			'overflow-y: hidden !important;'+
		'}'+
		'.kill-ie{'+
			'text-align:center;'+
			'height: 100%;'+
			'margin-top: 15%;'+
			'margin-bottom: 5500%;'+
		'}'+
    '.kill-t{'+
      'font-size: 2rem;'+
    '}'+
    '.kill-c{'+
      'font-size: 1.2rem;'+
    '}'+
		'#l_header,#l_body{'+
			'display: none;'+
		'}'+
	'</style>'+
    '<div class="kill-ie">'+
        `<span class="kill-t"><b>Sorry, your browser cannot access this site</b></span><br/>`+
        `<span class="kill-c">Microsoft has terminated support for Internet Explorer (IE) 10 and earlier versions in 2016. <br/>There are great security risks to continue using it. Please use contemporary mainstream browsers to access.</span><br/>`+
        `<a target="_blank" rel="noopener" href="https://blogs.windows.com/windowsexperience/2021/05/19/the-future-of-internet-explorer-on-windows-10-is-in-microsoft-edge/"><strong>Learn more ></strong></a>`+
    '</div>');
</script>


<noscript>
	<style>
		html{
			overflow-x: hidden !important;
			overflow-y: hidden !important;
		}
		.kill-noscript{
			text-align:center;
			height: 100%;
			margin-top: 15%;
			margin-bottom: 5500%;
		}
    .kill-t{
      font-size: 2rem;
    }
    .kill-c{
      font-size: 1.2rem;
    }
		#l_header,#l_body{
			display: none;
		}
	</style>
    <div class="kill-noscript">
        <span class="kill-t"><b>Sorry, your browser cannot access this site</b></span><br/>
        <span class="kill-c">This page requires browser support (enable) JavaScript</span><br/>
        <a target="_blank" rel="noopener" href="https://www.baidu.com/s?wd=启用JavaScript"><strong>Learn more ></strong></a>
    </div>
</noscript>


  <script>
  /************这个文件存放不需要重载的全局变量和全局函数*********/
  window.volantis = {}; // volantis 全局变量
  volantis.debug = "env"; // 调试模式
  volantis.dom = {}; // 页面Dom see: /source/js/app.js etc.

  volantis.GLOBAL_CONFIG ={
    debug: "env",
    cdn: {"js":{"app":"/js/app.js","parallax":"/js/plugins/parallax.js","rightMenu":"/js/plugins/rightMenu.js","rightMenus":"/js/plugins/rightMenus.js","sites":"/js/plugins/tags/sites.js","friends":"/js/plugins/tags/friends.js","contributors":"/js/plugins/tags/contributors.js","search":"/js/search/hexo.js"},"css":{"style":"/css/style.css"}},
    default: {"avatar":"https://unpkg.com/volantis-static@0.0.1654736714924/media/placeholder/avatar/round/3442075.svg","link":"https://unpkg.com/volantis-static@0.0.1654736714924/media/placeholder/link/8f277b4ee0ecd.svg","cover":"https://unpkg.com/volantis-static@0.0.1654736714924/media/placeholder/cover/76b86c0226ffd.svg","image":"https://unpkg.com/volantis-static@0.0.1654736714924/media/placeholder/image/2659360.svg"},
    lastupdate: new Date(1765549629403),
    sidebar: {
      for_page: ["blogger","category","tagcloud","webinfo","lastupdate"],
      for_post: ["toc"],
      webinfo: {
        lastupd: {
          enable: true,
          friendlyShow: true
        },
        runtime: {
          data: "2022/12/04",
          unit: "天"
        }
      }
    },
    plugins: {
      message: {"enable":true,"css":"https://unpkg.com/volantis-static@0.0.1654736714924/libs/izitoast/dist/css/iziToast.min.css","js":"https://unpkg.com/volantis-static@0.0.1654736714924/libs/izitoast/dist/js/iziToast.min.js","icon":{"default":"fa-solid fa-info-circle light-blue","quection":"fa-solid fa-question-circle light-blue"},"time":{"default":5000,"quection":20000},"position":"topRight","transitionIn":"bounceInLeft","transitionOut":"fadeOutRight","titleColor":"var(--color-text)","messageColor":"var(--color-text)","backgroundColor":"var(--color-card)","zindex":2147483647,"copyright":{"enable":true,"title":"知识共享许可协议","message":"请遵守 CC BY-NC-SA 4.0 协议。","icon":"far fa-copyright light-blue"},"aplayer":{"enable":true,"play":"fa-solid fa-play","pause":"fa-solid fa-pause"},"rightmenu":{"enable":true,"notice":true}},
      fancybox: {"css":"https://unpkg.com/volantis-static@0.0.1654736714924/libs/@fancyapps/ui/dist/fancybox.css","js":"https://unpkg.com/volantis-static@0.0.1654736714924/libs/@fancyapps/ui/dist/fancybox.umd.js"},
      
      aplayer: {
        id: 993524571,
        enable:true
      },
      
      
      
    }
  }

  /******************** volantis.EventListener ********************************/
  // 事件监听器 see: /source/js/app.js
  volantis.EventListener = {}
  // 这里存放pjax切换页面时将被移除的事件监听器
  volantis.EventListener.list = []
  //构造方法
  function volantisEventListener(type, f, ele) {
    this.type = type
    this.f = f
    this.ele = ele
  }
  // 移除事件监听器
  volantis.EventListener.remove = () => {
    volantis.EventListener.list.forEach(function (i) {
      i.ele.removeEventListener(i.type, i.f, false)
    })
    volantis.EventListener.list = []
  }
  /******************** volantis.dom.$ ********************************/
  // 注：这里没有选择器，也没有forEach一次只处理一个dom，这里重新封装主题常用的dom方法，返回的是dom对象，对象包含了以下方法，同时保留dom的原生API
  function volantisDom(ele) {
    if (!ele) ele = document.createElement("div")
    this.ele = ele;
    // ==============================================================
    this.ele.find = (c) => {
      let q = this.ele.querySelector(c)
      if (q)
        return new volantisDom(q)
    }
    // ==============================================================
    this.ele.hasClass = (c) => {
      return this.ele.className.match(new RegExp('(\\s|^)' + c + '(\\s|$)'));
    }
    this.ele.addClass = (c) => {
      this.ele.classList.add(c);
      return this.ele
    }
    this.ele.removeClass = (c) => {
      this.ele.classList.remove(c);
      return this.ele
    }
    this.ele.toggleClass = (c) => {
      if (this.ele.hasClass(c)) {
        this.ele.removeClass(c)
      } else {
        this.ele.addClass(c)
      }
      return this.ele
    }
    // ==============================================================
    // 参数 r 为 true 表示pjax切换页面时事件监听器将被移除，false不移除
    this.ele.on = (c, f, r = 1) => {
      this.ele.addEventListener(c, f, false)
      if (r) {
        volantis.EventListener.list.push(new volantisEventListener(c, f, this.ele))
      }
      return this.ele
    }
    this.ele.click = (f, r) => {
      this.ele.on("click", f, r)
      return this.ele
    }
    this.ele.scroll = (f, r) => {
      this.ele.on("scroll", f, r)
      return this.ele
    }
    // ==============================================================
    this.ele.html = (c) => {
      // if(c=== undefined){
      //   return this.ele.innerHTML
      // }else{
      this.ele.innerHTML = c
      return this.ele
      // }
    }
    // ==============================================================
    this.ele.hide = (c) => {
      this.ele.style.display = "none"
      return this.ele
    }
    this.ele.show = (c) => {
      this.ele.style.display = "block"
      return this.ele
    }
    // ==============================================================
    return this.ele
  }
  volantis.dom.$ = (ele) => {
    return !!ele ? new volantisDom(ele) : null;
  }
  /******************** RunItem ********************************/
  function RunItem() {
    this.list = []; // 存放回调函数
    this.start = () => {
      for (var i = 0; i < this.list.length; i++) {
        this.list[i].run();
      }
    };
    this.push = (fn, name, setRequestAnimationFrame = true) => {
      let myfn = fn
      if (setRequestAnimationFrame) {
        myfn = ()=>{
          volantis.requestAnimationFrame(fn)
        }
      }
      var f = new Item(myfn, name);
      this.list.push(f);
    };
    this.remove = (name) =>{
      for (let index = 0; index < this.list.length; index++) {
        const e = this.list[index];
        if (e.name == name) {
          this.list.splice(index,1);
        }
      }
    }
    // 构造一个可以run的对象
    function Item(fn, name) {
      // 函数名称
      this.name = name || fn.name;
      // run方法
      this.run = () => {
        try {
          fn()
        } catch (error) {
          console.log(error);
        }
      };
    }
  }
  /******************** Pjax ********************************/
  // /layout/_plugins/pjax/index.ejs
  // volantis.pjax.send(callBack[,"callBackName"]) 传入pjax:send回调函数
  // volantis.pjax.push(callBack[,"callBackName"]) 传入pjax:complete回调函数
  // volantis.pjax.error(callBack[,"callBackName"]) 传入pjax:error回调函数
  volantis.pjax = {};
  volantis.pjax.method = {
    complete: new RunItem(),
    error: new RunItem(),
    send: new RunItem(),
  };
  volantis.pjax = Object.assign(volantis.pjax, {
    push: volantis.pjax.method.complete.push,
    error: volantis.pjax.method.error.push,
    send: volantis.pjax.method.send.push,
  });
  /******************** RightMenu ********************************/
  // volantis.rightmenu.handle(callBack[,"callBackName"]) 外部菜单项控制
  // 可在 volantis.mouseEvent 处获取右键事件
  volantis.rightmenu = {};
  volantis.rightmenu.method = {
    handle: new RunItem(),
  }
  volantis.rightmenu = Object.assign(volantis.rightmenu, {
    handle: volantis.rightmenu.method.handle.push,
  });
  /********************  Dark Mode  ********************************/
  // /layout/_partial/scripts/darkmode.ejs
  // volantis.dark.mode 当前模式 dark or light
  // volantis.dark.toggle() 暗黑模式触发器
  // volantis.dark.push(callBack[,"callBackName"]) 传入触发器回调函数
  volantis.dark = {};
  volantis.dark.method = {
    toggle: new RunItem(),
  };
  volantis.dark = Object.assign(volantis.dark, {
    push: volantis.dark.method.toggle.push,
  });
  /********************  Message  ********************************/
  // VolantisApp.message
  /********************  isMobile  ********************************/
  // /source/js/app.js
  // volantis.isMobile
  // volantis.isMobileOld
  /********************脚本动态加载函数********************************/
  // volantis.js(src, cb)  cb 可以传入onload回调函数 或者 JSON对象 例如: volantis.js("src", ()=>{}) 或 volantis.js("src", {defer:true,onload:()=>{}})
  // volantis.css(src)

  // 返回Promise对象，如下方法同步加载资源，这利于处理文件资源之间的依赖关系，例如：APlayer 需要在 MetingJS 之前加载
  // (async () => {
  //     await volantis.js("...theme.plugins.aplayer.js.aplayer...")
  //     await volantis.js("...theme.plugins.aplayer.js.meting...")
  // })();

  // 已经加入了setTimeout
  volantis.js = (src, cb) => {
    return new Promise(resolve => {
      setTimeout(function () {
        var HEAD = document.getElementsByTagName("head")[0] || document.documentElement;
        var script = document.createElement("script");
        script.setAttribute("type", "text/javascript");
        if (cb) {
          if (JSON.stringify(cb)) {
            for (let p in cb) {
              if (p == "onload") {
                script[p] = () => {
                  cb[p]()
                  resolve()
                }
              } else {
                script[p] = cb[p]
                script.onload = resolve
              }
            }
          } else {
            script.onload = () => {
              cb()
              resolve()
            };
          }
        } else {
          script.onload = resolve
        }
        script.setAttribute("src", src);
        HEAD.appendChild(script);
      });
    });
  }
  volantis.css = (src) => {
    return new Promise(resolve => {
      setTimeout(function () {
        var link = document.createElement('link');
        link.rel = "stylesheet";
        link.href = src;
        link.onload = resolve;
        document.getElementsByTagName("head")[0].appendChild(link);
      });
    });
  }
  /********************按需加载的插件********************************/
  // volantis.import.jQuery().then(()=>{})
  volantis.import = {
    jQuery: () => {
      if (typeof jQuery == "undefined") {
        return volantis.js("https://unpkg.com/volantis-static@0.0.1654736714924/libs/jquery/dist/jquery.min.js")
      } else {
        return new Promise(resolve => {
          resolve()
        });
      }
    }
  }
  /********************** requestAnimationFrame ********************************/
  // 1、requestAnimationFrame 会把每一帧中的所有 DOM 操作集中起来，在一次重绘或回流中就完成，并且重绘或回流的时间间隔紧紧跟随浏览器的刷新频率，一般来说，这个频率为每秒60帧。
  // 2、在隐藏或不可见的元素中，requestAnimationFrame 将不会进行重绘或回流，这当然就意味着更少的的 cpu，gpu 和内存使用量。
  volantis.requestAnimationFrame = (fn)=>{
    if (!window.requestAnimationFrame) {
      window.requestAnimationFrame = window.requestAnimationFrame || window.mozRequestAnimationFrame || window.webkitRequestAnimationFrame;
    }
    window.requestAnimationFrame(fn)
  }
  /************************ layoutHelper *****************************************/
  volantis.layoutHelper = (helper, html, opt)=>{
    opt = Object.assign({clean:false, pjax:true}, opt)
    function myhelper(helper, html, clean) {
      volantis.tempDiv = document.createElement("div");
      volantis.tempDiv.innerHTML = html;
      let layoutHelper = document.querySelector("#layoutHelper-"+helper)
      if (layoutHelper) {
        if (clean) {
          layoutHelper.innerHTML = ""
        }
        layoutHelper.append(volantis.tempDiv);
      }
    }
    myhelper(helper, html, opt.clean)
    if (opt.pjax) {
      volantis.pjax.push(()=>{
        myhelper(helper, html, opt.clean)
      },"layoutHelper-"+helper)
    }
  }
  /****************************** 滚动事件处理 ****************************************/
  volantis.scroll = {
    engine: new RunItem(),
    unengine: new RunItem(),
  };
  volantis.scroll = Object.assign(volantis.scroll, {
    push: volantis.scroll.engine.push,
  });
  // 滚动条距离顶部的距离
  volantis.scroll.getScrollTop = () =>{
    let scrollPos;
    if (window.pageYOffset) {
      scrollPos = window.pageYOffset;
    } else if (document.compatMode && document.compatMode != 'BackCompat') {
      scrollPos = document.documentElement.scrollTop;
    } else if (document.body) {
      scrollPos = document.body.scrollTop;
    }
    return scrollPos;
  }
  // 使用 requestAnimationFrame 处理滚动事件
  // `volantis.scroll.del` 中存储了一个数值, 该数值检测一定时间间隔内滚动条滚动的位移, 数值的检测频率是浏览器的刷新频率. 数值为正数时, 表示向下滚动. 数值为负数时, 表示向上滚动.
  volantis.scroll.handleScrollEvents = () => {
    volantis.scroll.lastScrollTop = volantis.scroll.getScrollTop()
    function loop() {
      const scrollTop = volantis.scroll.getScrollTop();
      if (volantis.scroll.lastScrollTop !== scrollTop) {
        volantis.scroll.del = scrollTop - volantis.scroll.lastScrollTop;
        volantis.scroll.lastScrollTop = scrollTop;
        // if (volantis.scroll.del > 0) {
        //   console.log("向下滚动");
        // } else {
        //   console.log("向上滚动");
        // }
        // 注销过期的unengine未滚动事件
        volantis.scroll.unengine.list=[]
        volantis.scroll.engine.start();
      }else{
        volantis.scroll.unengine.start();
      }
      volantis.requestAnimationFrame(loop)
    }
    volantis.requestAnimationFrame(loop)
  }
  volantis.scroll.handleScrollEvents()
  volantis.scroll.ele = null;
  // 触发页面滚动至目标元素位置
  volantis.scroll.to = (ele, option = {}) => {
    if (!ele) return;
    volantis.scroll.ele = ele;
    // 默认配置
    opt = {
      top: ele.getBoundingClientRect().top + document.documentElement.scrollTop,
      behavior: "smooth"
    }
    // 定义配置
    if ("top" in option) {
      opt.top = option.top
    }
    if ("behavior" in option) {
      opt.behavior = option.behavior
    }
    if ("addTop" in option) {
      opt.top += option.addTop
    }
    if (!("observerDic" in option)) {
      option.observerDic = 100
    }
    // 滚动
    window.scrollTo(opt);
    // 监视器
    // 监视并矫正元素滚动到指定位置
    // 用于处理 lazyload 引起的 cls 导致的定位失败问题
    // option.observer = false
    if (option.observer) {
      setTimeout(() => {
        if (volantis.scroll.ele != ele) {
          return
        }
        volantis.scroll.unengine.push(() => {
          let me = ele.getBoundingClientRect().top
          if(!(me >= -option.observerDic && me <= option.observerDic)){
            volantis.scroll.to(ele, option)
          }
          volantis.scroll.unengine.remove("unengineObserver")
        },"unengineObserver")
      },1000)
    }
  }
  /********************** Content Visibility ********************************/
  // 见 source/css/first.styl 如果遇到任何问题 删除 .post-story 即可
  // 一个元素被声明 content-visibility 属性后 如果元素不在 viewport 中 浏览器不会计算其后代元素样式和属性 从而节省 Style & Layout 耗时
  // content-visibility 的副作用: 锚点失效 等等(实验初期 暂不明确), 使用此方法清除样式
  volantis.cleanContentVisibility = ()=>{
    if (document.querySelector(".post-story")) {
      console.log("cleanContentVisibility");
      document.querySelectorAll(".post-story").forEach(e=>{
        e.classList.remove("post-story")
      })
    }
  }
  /******************************************************************************/
  /******************************************************************************/
  /******************************************************************************/
  //图像加载出错时的处理
  function errorImgAvatar(img) {
    img.src = "https://unpkg.com/volantis-static@0.0.1654736714924/media/placeholder/avatar/round/3442075.svg";
    img.onerror = null;
  }
  function errorImgCover(img) {
    img.src = "https://unpkg.com/volantis-static@0.0.1654736714924/media/placeholder/cover/76b86c0226ffd.svg";
    img.onerror = null;
  }
  /******************************************************************************/
</script>

  <!-- import head_end begin -->
  <!-- import head_end end -->
  <!-- Custom Files headEnd begin-->
  
  <!-- Custom Files headEnd end-->
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://unpkg.com/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://unpkg.com/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>
  <body itemscope itemtype="http://schema.org/WebPage">
    <!-- import body_begin begin-->
    <!-- import body_begin end-->
    <!-- Custom Files bodyBegin begin-->
    
    <!-- Custom Files bodyBegin end-->
    <header itemscope itemtype="http://schema.org/WPHeader" id="l_header" class="l_header auto shadow floatable blur " style='opacity: 0' >
  <div class='container'>
  <div id='wrapper'>
    <div class='nav-sub'>
      <p class="title"></p>
      <ul class='switcher nav-list-h m-phone' id="pjax-header-nav-list">
        <li><a id="s-comment" class="fa-solid fa-comments fa-fw" target="_self"  href="/" onclick="return false;" title="comment"></a></li>
        
          <li><a id="s-toc" class="s-toc fa-solid fa-list fa-fw" target="_self"  href="/" onclick="return false;" title="toc"></a></li>
        
      </ul>
    </div>
		<div class="nav-main">
      
        
        <a class="title flat-box" target="_self" href='/'>
          
            <img no-lazy class='logo' src='https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/Logo-NavBar@3x.png'/>
          
          
          
        </a>
      

			<div class='menu navigation'>
				<ul class='nav-list-h m-pc'>
          
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover"
                href="/" title="博客"
                  
                  
                  
                    active-action="action-home"
                  >
                  <i class='fa-solid fa-rss fa-fw'></i>博客
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover"
                href="/categories/" title="分类"
                  
                  
                  
                    active-action="action-categories"
                  >
                  <i class='fa-solid fa-folder-open fa-fw'></i>分类
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover"
                href="/tags/" title="标签"
                  
                  
                  
                    active-action="action-tags"
                  >
                  <i class='fa-solid fa-tags fa-fw'></i>标签
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover"
                href="/archives/" title="归档"
                  
                  
                  
                    active-action="action-archives"
                  >
                  <i class='fa-solid fa-archive fa-fw'></i>归档
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover"
                href="/friends/" title="友链"
                  
                  
                  
                    active-action="action-friends"
                  >
                  <i class='fa-solid fa-link fa-fw'></i>友链
                </a>
                
              </li>
            
          
          
            
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover"
                href="/about/" title="关于"
                  
                  
                  
                    active-action="action-about"
                  >
                  <i class='fa-solid fa-info-circle fa-fw'></i>关于
                </a>
                
              </li>
            
          
          
				</ul>
			</div>
      
      <div class="m_search">
        <form name="searchform" class="form u-search-form">
          <i class="icon fa-solid fa-search fa-fw"></i>
          <input type="text" class="input u-search-input" placeholder="Search..." />
        </form>
      </div>
      

			<ul class='switcher nav-list-h m-phone'>
				
					<li><a class="s-search fa-solid fa-search fa-fw" target="_self" href="/" onclick="return false;" title="search"></a></li>
				
				<li>
          <a class="s-menu fa-solid fa-bars fa-fw" target="_self" href="/" onclick="return false;" title="menu"></a>
          <ul class="menu-phone list-v navigation white-box">
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover"
                href="/" title="博客"
                  
                  
                  
                    active-action="action-home"
                  >
                  <i class='fa-solid fa-rss fa-fw'></i>博客
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover"
                href="/categories/" title="分类"
                  
                  
                  
                    active-action="action-categories"
                  >
                  <i class='fa-solid fa-folder-open fa-fw'></i>分类
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover"
                href="/tags/" title="标签"
                  
                  
                  
                    active-action="action-tags"
                  >
                  <i class='fa-solid fa-tags fa-fw'></i>标签
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover"
                href="/archives/" title="归档"
                  
                  
                  
                    active-action="action-archives"
                  >
                  <i class='fa-solid fa-archive fa-fw'></i>归档
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover"
                href="/friends/" title="友链"
                  
                  
                  
                    active-action="action-friends"
                  >
                  <i class='fa-solid fa-link fa-fw'></i>友链
                </a>
                
              </li>
            
          
            
              
            
              <li>
                <a class="menuitem flat-box faa-parent animated-hover"
                href="/about/" title="关于"
                  
                  
                  
                    active-action="action-about"
                  >
                  <i class='fa-solid fa-info-circle fa-fw'></i>关于
                </a>
                
              </li>
            
          
            
          </ul>
        </li>
			</ul>

      <!-- Custom Files header begin -->
      
      <!-- Custom Files header end -->
		</div>
	</div>
  </div>
</header>

    <div id="l_body">
      <div id="l_cover">
  
    
      <!-- see: /layout/_partial/scripts/_ctrl/coverCtrl.ejs -->
      <div id="half" class='cover-wrapper post search' style="display: ;">
        
  <div id="parallax-window"></div>

<div class='cover-body'>
  <div class='top'>
    
    
      <p class="title">MengFanjun的博客</p>
    
    
  </div>
  <div class='bottom'>
    
      <div class="m_search">
        <form name="searchform" class="form u-search-form">
          <input type="text" class="input u-search-input" placeholder="搜一下" />
          <i class="icon fa-solid fa-search fa-fw"></i>
        </form>
      </div>
    
    <div class='menu navigation'>
      <div class='list-h'>
        
          
            <a href="/"
              
              
              active-action="action-home">
              <p>主页</p>
            </a>
          
            <a href="/tags/"
              
              
              active-action="action-tags">
              <p>标签</p>
            </a>
          
        
      </div>
    </div>
  </div>
</div>

        <div id="scroll-down" style="display: none;"><i class="fa fa-chevron-down scroll-down-effects"></i></div>
      </div>
    
  
</div>

      <div id="safearea">
        <div class="body-wrapper">
          
<div id="l_main" class=''>
  <article itemscope itemtype="http://schema.org/Article" class="article post white-box reveal md shadow floatable blur article-type-post" id="post" itemscope itemprop="blogPost">
  <link itemprop="mainEntityOfPage" href="https://mengfanjun020906.github.io/2025/10/02/Stanford CS336 assignment1（上）/">
  <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="MengFanjun的博客">
  </span>
  <span hidden itemprop="post" itemscope itemtype="http://schema.org/Post">
    <meta itemprop="name" content="MengFanjun的博客">
    <meta itemprop="description" content="20级通信工程大学生的个人博客">
  </span>
  


  
    <span hidden>
      <meta itemprop="image" content="https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/favicon/android-chrome-192x192.png">
    </span>
  
  <div class="article-meta" id="top">
    
    
    
      <h1 class="title" itemprop="name headline">
        Stanford CS336 assignment1（上）
      </h1>
      <div class='new-meta-box'>
        
          
            
<div class='new-meta-item author' itemprop="author" itemscope itemtype="http://schema.org/Person">
  <a itemprop="url" class='author' href="/" rel="nofollow">
    <img itemprop="image" src="https://pic.imgdb.cn/item/63f9926ef144a01007de7d7d.png" class="lazyload" data-srcset="https://pic.imgdb.cn/item/63f9926ef144a01007de7d7d.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
    <p itemprop="name">MengFanjun</p>
  </a>
</div>

          
        
          
            

          
        
          
            <div class="new-meta-item date" itemprop="dateCreated datePublished" datetime="2025-10-02T11:27:32+08:00">
  <a class='notlink'>
    <i class="fa-solid fa-calendar-alt fa-fw" aria-hidden="true"></i>
    <p>发布于：Oct 2, 2025</p>
  </a>
</div>

          
        
          
            
  <div class="new-meta-item wordcount">
    <a class='notlink'>
      <i class="fa-solid fa-keyboard fa-fw" aria-hidden="true"></i>
      <p>8.1k words</p>
    </a>
  </div>
  <div class="new-meta-item readtime">
    <a class='notlink'>
      <i class="fa-solid fa-hourglass-half fa-fw" aria-hidden="true"></i>
      <p>38 min</p>
    </a>
  </div>


          
        
          
            


<div class="new-meta-item browse">
  <a class='notlink'>
    <p>
      <i class="fa-solid fa-eye fa-fw" aria-hidden="true"></i>
      
      <span id="busuanzi_value_page_pv"><i class="fa-solid fa-loader fa-spin fa-fw" aria-hidden="true"></i></span>
      
      <span>次浏览</span>
    </p>
  </a>
</div>


          
        
        <!-- Custom Files topMeta begin-->
        
        <!-- Custom Files topMeta end-->
      </div>
    
  </div>


  <div id="layoutHelper-page-plugins"></div>
  <div id="post-body" itemprop="articleBody">
    <p>源仓库链接：<a target="_blank" rel="noopener" href="https://github.com/stanford-cs336/assignment1-basics">https://github.com/stanford-cs336/assignment1-basics</a></p>
<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p><img src="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/0ba7f7461c49458894a4780760cb2c29.png" class="lazyload" data-srcset="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/0ba7f7461c49458894a4780760cb2c29.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="在这里插入图片描述"></p>
<h1 id="Byte-Pair-Encoding-BPE-Tokenizer"><a href="#Byte-Pair-Encoding-BPE-Tokenizer" class="headerlink" title="Byte-Pair Encoding (BPE) Tokenizer"></a>Byte-Pair Encoding (BPE) Tokenizer</h1><h2 id="The-Unicode-Standard"><a href="#The-Unicode-Standard" class="headerlink" title="The Unicode Standard"></a>The Unicode Standard</h2><p><img src="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/f8d1461e17dc42678fd5aaab4d2abbae.png" class="lazyload" data-srcset="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/f8d1461e17dc42678fd5aaab4d2abbae.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="在这里插入图片描述"><br>(a)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">chr</span>(<span class="number">0</span>)</span><br><span class="line"><span class="string">&#x27;\x00&#x27;</span></span><br></pre></td></tr></table></figure>
<p>(b)<br>_<em>repr</em>_ (字符串表示)：目标是明确和无歧义。它的主要受众是开发者，用于调试和日志记录。理想情况下，它应该返回一个字符串，让你能通过这个字符串重新创建出这个对象。<br>_<em>str</em>_ (打印表示)：目标是可读性好。它的主要受众是最终用户。当你使用 print(obj) 或 str(obj) 时，调用的是这个方法，它应该返回一个对用户友好、易于理解的字符串。<br>(c)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">chr</span>(<span class="number">0</span>)</span><br><span class="line"><span class="string">&#x27;\x00&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="built_in">chr</span>(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">&quot;this is a test&quot;</span> + <span class="built_in">chr</span>(<span class="number">0</span>) + <span class="string">&quot;string&quot;</span></span><br><span class="line"><span class="string">&#x27;this is a test\x00string&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="string">&quot;this is a test&quot;</span> + <span class="built_in">chr</span>(<span class="number">0</span>) + <span class="string">&quot;string&quot;</span>)</span><br><span class="line">this <span class="keyword">is</span> a teststring</span><br></pre></td></tr></table></figure>
<p><img src="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/09cb7138dd6c481bb32738e125d4a1bd.png" class="lazyload" data-srcset="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/09cb7138dd6c481bb32738e125d4a1bd.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="在这里插入图片描述"></p>
<p>(a)<br>UTF-8 是可变长度编码，对于 ASCII 字符（如英文字母、数字、常见符号）只使用 1 个字节，这些字符在大多数文本中占比较高。这使得 UTF-8 编码的文本通常更小，减少了存储和传输开销，从而提高了 tokenizer 训练的效率。</p>
<p>UTF-16 对于基本多文种平面（BMP）中的字符使用 2 字节，对于辅助平面中的字符使用 4 字节（通过代理对）。对于英文文本，UTF-16 通常比 UTF-8 大，因为 ASCII 字符在 UTF-16 中也需要 2 字节。</p>
<p>UTF-32 始终使用 4 字节 per character，这非常浪费空间。例如，ASCII 文本在 UTF-32 中会变大 4 倍，导致处理速度慢和存储成本高。<br>(b)<br>函数是错的，因为它试图逐个字节解码UTF-8字节串。但UTF-8是一种可变长度编码，一个字符可能由多个字节组成。如果逐个字节解码，那些多字节字符会被错误地解码成多个单独的字符，而不是一个正确的Unicode字符。<br>输入“中”字，其UTF-8编码是<code>b&#39;\xe4\xb8\xad&#39;</code><br>函数会将其解析为<code>0xe4, 0xb8, 0xad</code><br>报错输出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UnicodeDecodeError: <span class="string">&#x27;utf-8&#x27;</span> codec can<span class="string">&#x27;t decode byte 0xe4 in position 0: unexpected end of data</span></span><br></pre></td></tr></table></figure>
<p>(c)<br>一个两字节序列的例子是 0xD8 0x00（UTF-16 大端序），它解码为高代理码点 U+D800，该码点在没有对应低代理码位的情况下是无效的，不代表任何 Unicode 字符。</p>
<h1 id="BPE算法示例说明"><a href="#BPE算法示例说明" class="headerlink" title="BPE算法示例说明"></a>BPE算法示例说明</h1><p>以下内容基于Sennrich等人[2016]的论文中的一个简化示例，说明Byte Pair Encoding（BPE）算法的工作过程。</p>
<h2 id="语料库文本"><a href="#语料库文本" class="headerlink" title="语料库文本"></a>语料库文本</h2><p>假设语料库由以下文本组成：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">low low low low low</span><br><span class="line">lower lower widest widest widest</span><br><span class="line">newest newest newest newest newest newest</span><br></pre></td></tr></table></figure>
<p>此外，词汇表包含一个特殊标记<code>&lt;|endoftext|&gt;</code>。</p>
<h2 id="词汇表初始化"><a href="#词汇表初始化" class="headerlink" title="词汇表初始化"></a>词汇表初始化</h2><p>词汇表初始时包含特殊标记<code>&lt;|endoftext|&gt;</code>和256个字节值（即所有可能的字节字符）。</p>
<h2 id="预分词"><a href="#预分词" class="headerlink" title="预分词"></a>预分词</h2><p>为简化起见，预分词过程仅基于空格进行分割。分割后，我们得到以下单词频率表：</p>
<ul>
<li><code>low</code>：出现5次</li>
<li><code>lower</code>：出现2次</li>
<li><code>widest</code>：出现3次</li>
<li><code>newest</code>：出现6次</li>
</ul>
<p>在Python中，这些单词被表示为字节元组（每个字节是一个bytes对象）。例如：</p>
<ul>
<li><code>low</code> 表示为 <code>(l, o, w)</code></li>
<li><code>lower</code> 表示为 <code>(l, o, w, e, r)</code></li>
<li><code>widest</code> 表示为 <code>(w, i, d, e, s, t)</code></li>
<li><code>newest</code> 表示为 <code>(n, e, w, e, s, t)</code></li>
</ul>
<h2 id="合并过程"><a href="#合并过程" class="headerlink" title="合并过程"></a>合并过程</h2><p>BPE算法通过迭代合并最常见字节对来构建词汇表。</p>
<h3 id="第一轮合并"><a href="#第一轮合并" class="headerlink" title="第一轮合并"></a>第一轮合并</h3><p>首先，统计所有相邻字节对的频率（基于单词频率）：</p>
<ul>
<li><code>lo</code>：7（出现在<code>low</code>和<code>lower</code>中）</li>
<li><code>ow</code>：7（出现在<code>low</code>和<code>lower</code>中）</li>
<li><code>we</code>：8（出现在<code>widest</code>和<code>newest</code>中）</li>
<li><code>er</code>：2（出现在<code>lower</code>中）</li>
<li><code>wi</code>：3（出现在<code>widest</code>中）</li>
<li><code>id</code>：3（出现在<code>widest</code>中）</li>
<li><code>de</code>：3（出现在<code>widest</code>中）</li>
<li><code>es</code>：9（出现在<code>widest</code>和<code>newest</code>中）</li>
<li><code>st</code>：9（出现在<code>widest</code>和<code>newest</code>中）</li>
<li><code>ne</code>：6（出现在<code>newest</code>中）</li>
<li><code>ew</code>：6（出现在<code>newest</code>中）</li>
</ul>
<p>频率最高的对是<code>es</code>和<code>st</code>，频率均为9。由于平局，选择字典序较大的对，即<code>st</code>（因为<code>s</code>在字母表中位于<code>e</code>之后）。因此，合并<code>st</code>为单个单元。</p>
<p>合并后，单词表示为：</p>
<ul>
<li><code>(l, o, w)</code>：5次</li>
<li><code>(l, o, w, e, r)</code>：2次</li>
<li><code>(w, i, d, e, st)</code>：3次（<code>st</code>被合并）</li>
<li><code>(n, e, w, e, st)</code>：6次（<code>st</code>被合并）</li>
</ul>
<h3 id="第二轮合并"><a href="#第二轮合并" class="headerlink" title="第二轮合并"></a>第二轮合并</h3><p>现在，统计新的字节对频率。注意，<code>e</code>和<code>st</code>现在相邻，对<code>e st</code>的频率为9（出现在<code>widest</code>和<code>newest</code>中），是最常见的对。因此，合并<code>e st</code>为<code>est</code>。</p>
<p>合并后，单词表示为：</p>
<ul>
<li><code>(l, o, w)</code>：5次</li>
<li><code>(l, o, w, e, r)</code>：2次</li>
<li><code>(w, i, d, est)</code>：3次（<code>est</code>被合并）</li>
<li><code>(n, e, w, est)</code>：6次（<code>est</code>被合并）</li>
</ul>
<h3 id="后续合并"><a href="#后续合并" class="headerlink" title="后续合并"></a>后续合并</h3><p>继续此过程，最终的合并序列为：</p>
<ol>
<li>合并<code>s t</code>为<code>st</code></li>
<li>合并<code>e st</code>为<code>est</code></li>
<li>合并<code>o w</code>为<code>ow</code></li>
<li>合并<code>l ow</code>为<code>low</code></li>
<li>合并<code>w est</code>为<code>west</code></li>
<li>合并<code>n e</code>为<code>ne</code></li>
<li>合并<code>ne west</code>为<code>newest</code>（但注意，在合并过程中，步骤可能不同）</li>
<li>合并<code>w i</code>为<code>wi</code></li>
<li>合并<code>wi d</code>为<code>wid</code></li>
<li>合并<code>wid est</code>为<code>widest</code></li>
<li>合并<code>low e</code>为<code>lowe</code></li>
<li>合并<code>lowe r</code>为<code>lower</code></li>
</ol>
<h3 id="合并6次后的词汇表"><a href="#合并6次后的词汇表" class="headerlink" title="合并6次后的词汇表"></a>合并6次后的词汇表</h3><p>如果只进行6次合并，合并序列为：<code>[&#39;s t&#39;, &#39;e st&#39;, &#39;o w&#39;, &#39;l ow&#39;, &#39;w est&#39;, &#39;n e&#39;]</code>。此时，词汇表包含：</p>
<ul>
<li>特殊标记<code>&lt;|endoftext|&gt;</code></li>
<li>256个字节字符</li>
<li>合并后的单元：<code>st</code>, <code>est</code>, <code>ow</code>, <code>low</code>, <code>west</code>, <code>ne</code></li>
</ul>
<p>使用此词汇表和合并规则，单词<code>newest</code>会被分词为<code>[ne, west]</code>。</p>
<p>此示例展示了BPE如何通过迭代合并常见字节对来构建子词词汇表。</p>
<p><img src="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/00854749be494e8a89442f7b2b126ebd.png" class="lazyload" data-srcset="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/00854749be494e8a89442f7b2b126ebd.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="在这里插入图片描述"><br>我们需要实现的是一个这样的函数<code>train_bpe</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vocab, merges = train_bpe(input_path, vocab_size, special_tokens)</span><br></pre></td></tr></table></figure>
<p>然后给他写进adpaters.py去做测试<br>参考了网上的几个大神的作业<br>tokenizer.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Dict</span>, <span class="type">Tuple</span>, <span class="type">List</span>, Iterable, Iterator</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">import</span> regex <span class="keyword">as</span> re</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> queue <span class="keyword">import</span> Empty</span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process, Queue, Manager</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> trange, tqdm</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> cs336_basics.tokenizer.pretokenization_regular_pattern <span class="keyword">import</span> PAT</span><br><span class="line"><span class="keyword">from</span> cs336_basics.tokenizer.utils <span class="keyword">import</span> find_chunk_boundaries </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">initialize_vocab</span>(<span class="params">special_tokens: <span class="type">List</span>[<span class="built_in">bytes</span>]</span>) -&gt; <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="built_in">bytes</span>]:</span><br><span class="line">    vocab = &#123;i: <span class="built_in">bytes</span>([i]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">256</span>)&#125;  <span class="comment"># ASCII characters</span></span><br><span class="line">    <span class="keyword">for</span> i, token <span class="keyword">in</span> <span class="built_in">enumerate</span>(special_tokens, start=<span class="number">256</span>):</span><br><span class="line">        vocab[i] = token</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> vocab</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">word_to_bytes</span>(<span class="params">word: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">bytes</span>]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Convert a word to bytes.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    byte_ids = [<span class="built_in">bytes</span>([b]) <span class="keyword">for</span> b <span class="keyword">in</span> word.encode(<span class="string">&quot;utf-8&quot;</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> byte_ids</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">split_by_special_tokens</span>(<span class="params"></span></span><br><span class="line"><span class="params">    text: <span class="built_in">str</span>, special_tokens: <span class="built_in">list</span>[<span class="built_in">str</span>]</span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="type">List</span>[<span class="built_in">str</span>]:</span><br><span class="line">    special_tokens_sorted = <span class="built_in">sorted</span>(special_tokens, key=<span class="built_in">len</span>, reverse=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> special_tokens_sorted:</span><br><span class="line">        <span class="keyword">return</span> [text]</span><br><span class="line">    pattern = <span class="string">&quot;|&quot;</span>.join(re.escape(t) <span class="keyword">for</span> t <span class="keyword">in</span> special_tokens_sorted)</span><br><span class="line">    special_chunks = re.split(<span class="string">f&quot;(<span class="subst">&#123;pattern&#125;</span>)&quot;</span>, text)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> special_chunks</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pre_tokenize_string</span>(<span class="params">text: <span class="built_in">str</span>, special_tokens: <span class="type">List</span>[<span class="built_in">str</span>], include_special: <span class="built_in">bool</span> = <span class="literal">False</span></span>) -&gt; Counter:</span><br><span class="line">    word_counter = Counter()</span><br><span class="line">    special_chunks = split_by_special_tokens(text, special_tokens)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> chunk <span class="keyword">in</span> special_chunks:</span><br><span class="line">        <span class="keyword">if</span> chunk <span class="keyword">in</span> special_tokens:</span><br><span class="line">            <span class="keyword">if</span> include_special:</span><br><span class="line">                token = <span class="built_in">tuple</span>(word_to_bytes(chunk))</span><br><span class="line">                word_counter[token] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">for</span> <span class="keyword">match</span> <span class="keyword">in</span> re.finditer(PAT, chunk):</span><br><span class="line">                word = <span class="keyword">match</span>.group(<span class="number">0</span>)</span><br><span class="line">                token = <span class="built_in">tuple</span>(word_to_bytes(word))</span><br><span class="line">                word_counter[token] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> word_counter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># <span class="doctag">TODO:</span> Implement the worker for this.</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pre_tokenize_string_worker</span>(<span class="params"></span></span><br><span class="line"><span class="params">    input_path: <span class="built_in">str</span> | os.PathLike, special_tokens: <span class="built_in">list</span>[<span class="built_in">str</span>], queue: Queue, start: <span class="built_in">int</span>, end: <span class="built_in">int</span>, include_special: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Pre-tokenize a string into bytes.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(input_path, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.seek(start)</span><br><span class="line">        chunk = f.read(end - start).decode(<span class="string">&quot;utf-8&quot;</span>, errors=<span class="string">&quot;ignore&quot;</span>)</span><br><span class="line">        </span><br><span class="line">    word_counter = pre_tokenize_string(chunk, special_tokens, include_special)</span><br><span class="line">                </span><br><span class="line">    <span class="comment"># Put the result in the queue</span></span><br><span class="line">    queue.put(word_counter)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pair_counts</span>(<span class="params"></span></span><br><span class="line"><span class="params">    word_counter: <span class="type">Dict</span>[<span class="type">Tuple</span>[<span class="built_in">bytes</span>], <span class="built_in">int</span>],</span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="type">Dict</span>[<span class="type">Tuple</span>[<span class="built_in">bytes</span>, <span class="built_in">bytes</span>], <span class="built_in">int</span>]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Count pairs of bytes in the word counter.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    pairs: <span class="type">Dict</span>[<span class="type">Tuple</span>[<span class="built_in">bytes</span>, <span class="built_in">bytes</span>], <span class="built_in">int</span>] = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> token, freq <span class="keyword">in</span> word_counter.items():</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(token) - <span class="number">1</span>):</span><br><span class="line">            pair = (token[i], token[i + <span class="number">1</span>])</span><br><span class="line">            pairs[pair] = pairs.get(pair, <span class="number">0</span>) + freq</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> pairs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_most_frequent_pair</span>(<span class="params"></span></span><br><span class="line"><span class="params">    pairs: <span class="type">Dict</span>[<span class="type">Tuple</span>[<span class="built_in">bytes</span>, <span class="built_in">bytes</span>], <span class="built_in">int</span>],</span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="type">Tuple</span>[<span class="built_in">bytes</span>, <span class="built_in">bytes</span>]:</span><br><span class="line">    max_freq = <span class="built_in">max</span>(pairs.values())</span><br><span class="line">    candidates = [pair <span class="keyword">for</span> pair, freq <span class="keyword">in</span> pairs.items() <span class="keyword">if</span> freq == max_freq]</span><br><span class="line">    res = <span class="built_in">max</span>(candidates)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_pair_to_vocab</span>(<span class="params"></span></span><br><span class="line"><span class="params">    vocab: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="built_in">bytes</span>], pair: <span class="type">Tuple</span>[<span class="built_in">bytes</span>, <span class="built_in">bytes</span>], vocab_inv: <span class="type">Dict</span>[<span class="built_in">bytes</span>, <span class="built_in">int</span>]</span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Add a new pair to the vocabulary.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    index = <span class="built_in">len</span>(vocab)</span><br><span class="line">    s = vocab[vocab_inv[pair[<span class="number">0</span>]]] + vocab[vocab_inv[pair[<span class="number">1</span>]]]</span><br><span class="line">    vocab[index] = s</span><br><span class="line">    vocab_inv[vocab[index]] = index</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> index</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter, defaultdict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">merge_pair</span>(<span class="params"></span></span><br><span class="line"><span class="params">    word_counter: <span class="type">Dict</span>[<span class="type">Tuple</span>[<span class="built_in">bytes</span>], <span class="built_in">int</span>], pair: <span class="type">Tuple</span>[<span class="built_in">bytes</span>, <span class="built_in">bytes</span>]</span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="type">Tuple</span>[<span class="type">Dict</span>[<span class="type">Tuple</span>[<span class="built_in">bytes</span>], <span class="built_in">int</span>], <span class="type">Dict</span>]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Merge a pair of bytes in the word counter.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    new_word_counter = Counter()</span><br><span class="line">    updated_pair_counts = defaultdict(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> token, freq <span class="keyword">in</span> word_counter.items():</span><br><span class="line">        new_token = []</span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> i &lt; <span class="built_in">len</span>(token):</span><br><span class="line">            <span class="keyword">if</span> i &lt; <span class="built_in">len</span>(token) - <span class="number">1</span> <span class="keyword">and</span> (token[i], token[i + <span class="number">1</span>]) == pair:</span><br><span class="line">                new_token.append(token[i] + token[i + <span class="number">1</span>])</span><br><span class="line">                i += <span class="number">2</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                new_token.append(token[i])</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        new_word_counter[<span class="built_in">tuple</span>(new_token)] += freq</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(new_token) - <span class="number">1</span>):</span><br><span class="line">            new_pair = (new_token[j], new_token[j + <span class="number">1</span>])</span><br><span class="line">            updated_pair_counts[new_pair] += freq</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> new_word_counter, updated_pair_counts</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">check_and_convert_special_tokens</span>(<span class="params"></span></span><br><span class="line"><span class="params">    special_tokens: <span class="type">List</span>[<span class="built_in">str</span>] | <span class="type">List</span>[<span class="built_in">bytes</span>],</span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="type">List</span>[<span class="built_in">bytes</span>]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Check if special tokens are in the vocabulary and convert them to bytes.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">all</span>(<span class="built_in">isinstance</span>(token, <span class="built_in">bytes</span>) <span class="keyword">for</span> token <span class="keyword">in</span> special_tokens):</span><br><span class="line">        special_tokens_bytes = [</span><br><span class="line">            token.encode(<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">for</span> token <span class="keyword">in</span> special_tokens <span class="keyword">if</span> <span class="built_in">isinstance</span>(token, <span class="built_in">str</span>)</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> special_tokens_bytes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_bpe</span>(<span class="params"></span></span><br><span class="line"><span class="params">    input_path: <span class="built_in">str</span> | os.PathLike ,</span></span><br><span class="line"><span class="params">    vocab_size=<span class="number">10_000</span>,</span></span><br><span class="line"><span class="params">    special_tokens: <span class="type">List</span>[<span class="built_in">str</span>] = [],</span></span><br><span class="line"><span class="params">    **kwargs,</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    special_tokens_bytes = check_and_convert_special_tokens(special_tokens)</span><br><span class="line"></span><br><span class="line">    vocab = initialize_vocab(special_tokens_bytes)</span><br><span class="line">    vocab_inv = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> vocab.items()&#125;</span><br><span class="line">    merges: <span class="type">List</span>[<span class="type">Tuple</span>[<span class="built_in">bytes</span>, <span class="built_in">bytes</span>]] = []</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Pre-tokenization</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(input_path, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        chunk_boundaries = find_chunk_boundaries(</span><br><span class="line">            f, kwargs.get(<span class="string">&quot;num_processes&quot;</span>, <span class="number">8</span>), special_tokens_bytes[<span class="number">0</span>]</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    manager = Manager()</span><br><span class="line">    queue = manager.Queue()</span><br><span class="line">    processes = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> start, end <span class="keyword">in</span> <span class="built_in">zip</span>(chunk_boundaries[:-<span class="number">1</span>], chunk_boundaries[<span class="number">1</span>:]):</span><br><span class="line">        p = Process(</span><br><span class="line">            target=pre_tokenize_string_worker,</span><br><span class="line">            args=(input_path, special_tokens, queue, start, end, <span class="literal">False</span>),</span><br><span class="line">        )</span><br><span class="line">        processes.append(p)</span><br><span class="line">        p.start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> processes:</span><br><span class="line">        p.join()</span><br><span class="line">        </span><br><span class="line">    word_counter = Counter()</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(processes)):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            word_counter += queue.get(timeout=<span class="number">10</span>)  <span class="comment"># Wait up to 10 seconds for results</span></span><br><span class="line">        <span class="keyword">except</span> Empty:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;⚠️ Warning: A subprocess did not return a result!&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># End Pre-tokenization</span></span><br><span class="line"></span><br><span class="line">    pairs_freqs = pair_counts(word_counter)</span><br><span class="line">    </span><br><span class="line">    num_merges = vocab_size - <span class="built_in">len</span>(vocab)</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> trange(num_merges):</span><br><span class="line"></span><br><span class="line">        most_common_pair = get_most_frequent_pair(pairs_freqs)</span><br><span class="line"></span><br><span class="line">        new_index = add_pair_to_vocab(vocab, most_common_pair, vocab_inv)</span><br><span class="line">        merges.append(most_common_pair)</span><br><span class="line"></span><br><span class="line">        word_counter, pairs_freqs = merge_pair(word_counter, most_common_pair)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> vocab, merges</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Tokenizer</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self, </span></span><br><span class="line"><span class="params">        vocab: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="built_in">bytes</span>], </span></span><br><span class="line"><span class="params">        merges: <span class="type">List</span>[<span class="type">Tuple</span>[<span class="built_in">bytes</span>, <span class="built_in">bytes</span>]],</span></span><br><span class="line"><span class="params">        special_tokens: <span class="type">List</span>[<span class="built_in">str</span>] | <span class="literal">None</span> = []</span></span><br><span class="line"><span class="params">    </span>):</span><br><span class="line">        self.vocab = vocab</span><br><span class="line">        self.merges = merges</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># self.register_special_tokens(special_tokens)</span></span><br><span class="line">        self.vocab_inv = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> self.vocab.items()&#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> special_tokens <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            self.special_tokens = &#123;&#125;</span><br><span class="line">            self.bytes_special_tokens = []</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.special_tokens = &#123;token: i <span class="keyword">for</span> i, token <span class="keyword">in</span> <span class="built_in">enumerate</span>(special_tokens, start=<span class="built_in">len</span>(self.vocab))&#125;</span><br><span class="line">            self.bytes_special_tokens = [token.encode(<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">for</span> token <span class="keyword">in</span> special_tokens <span class="keyword">if</span> <span class="built_in">isinstance</span>(token, <span class="built_in">str</span>)]</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">register_special_tokens</span>(<span class="params">self, special_tokens</span>):</span><br><span class="line">        <span class="keyword">if</span> special_tokens <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            self.special_tokens = &#123;&#125;</span><br><span class="line">            self.bytes_special_tokens = []</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">all</span>(<span class="built_in">isinstance</span>(token, <span class="built_in">bytes</span>) <span class="keyword">for</span> token <span class="keyword">in</span> special_tokens):</span><br><span class="line">            bytes_special_tokens = [token.encode(<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">for</span> token <span class="keyword">in</span> special_tokens <span class="keyword">if</span> <span class="built_in">isinstance</span>(token, <span class="built_in">str</span>)]</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">for</span> i, token <span class="keyword">in</span> <span class="built_in">enumerate</span>(bytes_special_tokens, start=<span class="built_in">len</span>(self.vocab)):</span><br><span class="line">            <span class="comment"># Add special tokens to the vocabulary</span></span><br><span class="line">            self.vocab[i] = token</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># self.bytes_special_tokens = bytes_special_tokens</span></span><br><span class="line">        <span class="comment"># self.special_tokens = &#123;token: i for i, token in enumerate(special_tokens, start=len(self.vocab))&#125;</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_pre_tokenize</span>(<span class="params">self, text</span>) -&gt; <span class="type">List</span>[<span class="built_in">bytes</span>]:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Pre-tokenize the input text into bytes.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        parts = split_by_special_tokens(text, <span class="built_in">list</span>(self.special_tokens.keys()))</span><br><span class="line">        token_list = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> part <span class="keyword">in</span> parts:</span><br><span class="line">            <span class="keyword">if</span> part <span class="keyword">in</span> self.special_tokens.keys():</span><br><span class="line">                token_list.append(part.encode(<span class="string">&quot;utf-8&quot;</span>))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                tokens = re.findall(PAT, part)</span><br><span class="line">                token_list.extend(word_to_bytes(token) <span class="keyword">for</span> token <span class="keyword">in</span> tokens)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> token_list</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">encode</span>(<span class="params">self, text: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        byte_tokens = self._pre_tokenize(text)</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># Convert byte tokens to indices</span></span><br><span class="line">        token_ids = []</span><br><span class="line">        <span class="keyword">for</span> byte_token <span class="keyword">in</span> byte_tokens:</span><br><span class="line">            <span class="comment"># print(f&quot;Processing byte token: &#123;byte_token&#125;&quot;)</span></span><br><span class="line">            <span class="keyword">if</span> byte_token <span class="keyword">in</span> self.bytes_special_tokens:</span><br><span class="line">                token_ids.append([self.vocab_inv[byte_token]])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                token_ids.append([self.vocab_inv[b] <span class="keyword">for</span> b <span class="keyword">in</span> byte_token]) <span class="comment">#type: ignore</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i, pretoken <span class="keyword">in</span> <span class="built_in">enumerate</span>(token_ids):</span><br><span class="line">            <span class="keyword">for</span> merge <span class="keyword">in</span> self.merges:</span><br><span class="line">                new_index = self.vocab_inv.get(merge[<span class="number">0</span>] + merge[<span class="number">1</span>], <span class="literal">None</span>)</span><br><span class="line">                <span class="keyword">if</span> new_index <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">                merged = []</span><br><span class="line">                j = <span class="number">0</span></span><br><span class="line">                <span class="keyword">while</span> j &lt; <span class="built_in">len</span>(pretoken):</span><br><span class="line">                    <span class="keyword">if</span> (</span><br><span class="line">                        j &lt; <span class="built_in">len</span>(pretoken) - <span class="number">1</span></span><br><span class="line">                        <span class="keyword">and</span> (self.vocab[pretoken[j]], self.vocab[pretoken[j + <span class="number">1</span>]]) == merge</span><br><span class="line">                    ):</span><br><span class="line">                        merged.append(new_index)</span><br><span class="line">                        j += <span class="number">2</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        merged.append(pretoken[j])</span><br><span class="line">                        j += <span class="number">1</span></span><br><span class="line">                        </span><br><span class="line">                pretoken = merged</span><br><span class="line">            token_ids[i] = pretoken[:]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> [i <span class="keyword">for</span> pre <span class="keyword">in</span> token_ids <span class="keyword">for</span> i <span class="keyword">in</span> pre]</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">encode_iterable</span>(<span class="params">self, iterable: Iterable[<span class="built_in">str</span>], batch_size: <span class="built_in">int</span> = <span class="number">1024</span></span>) -&gt; Iterator[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Encode lines of text from an iterable using buffered batching.</span></span><br><span class="line"><span class="string">        This version preserves newlines by assuming the input was split with `splitlines(keepends=True)`.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        batch = []</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> tqdm(iterable):</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> line:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            batch.append(line)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(batch) &gt;= batch_size:</span><br><span class="line">                <span class="keyword">for</span> encoded <span class="keyword">in</span> <span class="built_in">map</span>(self.encode, batch):</span><br><span class="line">                    <span class="keyword">yield</span> <span class="keyword">from</span> encoded</span><br><span class="line">                batch.clear()</span><br><span class="line">                </span><br><span class="line">        <span class="keyword">if</span> batch:</span><br><span class="line">            <span class="keyword">for</span> encoded <span class="keyword">in</span> <span class="built_in">map</span>(self.encode, batch):</span><br><span class="line">                <span class="keyword">yield</span> <span class="keyword">from</span> encoded</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">decode</span>(<span class="params">self, ids: <span class="built_in">list</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="comment"># https://en.wikipedia.org/wiki/Specials_(Unicode_block)#Replacement_character</span></span><br><span class="line">        </span><br><span class="line">        tokens = <span class="string">b&quot;&quot;</span>.join(self.vocab.get(i, <span class="string">b&quot;\xef\xbf\xbd&quot;</span>) <span class="keyword">for</span> i <span class="keyword">in</span> ids)</span><br><span class="line">        <span class="keyword">return</span> tokens.decode(<span class="string">&quot;utf-8&quot;</span>, errors=<span class="string">&quot;replace&quot;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">from_files</span>(<span class="params"></span></span><br><span class="line"><span class="params">        cls, vocab_path: <span class="built_in">str</span>, merges_path: <span class="built_in">str</span>, special_tokens: <span class="built_in">list</span>[<span class="built_in">str</span>] | <span class="literal">None</span> = <span class="literal">None</span></span></span><br><span class="line"><span class="params">    </span>):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(vocab_path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> vf:</span><br><span class="line">            raw_vocab = pickle.load(vf)</span><br><span class="line"></span><br><span class="line">        vocab = &#123;<span class="built_in">int</span>(k): (v.encode(<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">if</span> <span class="built_in">isinstance</span>(v, <span class="built_in">str</span>) <span class="keyword">else</span> v)</span><br><span class="line">                <span class="keyword">for</span> k, v <span class="keyword">in</span> raw_vocab.items()&#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(merges_path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> mf:</span><br><span class="line">            raw_merges = pickle.load(mf)</span><br><span class="line"></span><br><span class="line">        merges = []</span><br><span class="line">        <span class="keyword">for</span> a, b <span class="keyword">in</span> raw_merges:</span><br><span class="line">            merges.append((</span><br><span class="line">                a.encode(<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">if</span> <span class="built_in">isinstance</span>(a, <span class="built_in">str</span>) <span class="keyword">else</span> a,</span><br><span class="line">                b.encode(<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">if</span> <span class="built_in">isinstance</span>(b, <span class="built_in">str</span>) <span class="keyword">else</span> b</span><br><span class="line">            ))</span><br><span class="line">        <span class="keyword">return</span> cls(vocab, merges, special_tokens)</span><br></pre></td></tr></table></figure>
<p>初始化与辅助函数：<br>initialize_vocab: 初始化基础词汇表（256个ASCII字符 + 特殊令牌）。</p>
<p>word_to_bytes: 将字符串转换为UTF-8字节序列。</p>
<p>split_by_special_tokens: 用正则表达式按特殊令牌分割文本。</p>
<p>pre_tokenize_string: 将文本按规则预分词（使用正则模式PAT，用于把输入的内容和标点符号分割成有意义的部分）并统计词频。<br>多进程处理：<br>pre_tokenize_string_worker: 多进程 worker 函数，处理文件块并统计词频。</p>
<p>使用multiprocessing.Queue收集结果，tqdm显示进度条。<br>BPE的核心函数：<br>pair_counts: 统计相邻字节对的频率。</p>
<p>get_most_frequent_pair: 找到最高频的字节对。</p>
<p>merge_pair: 合并字节对并更新词频统计。</p>
<p>add_pair_to_vocab: 将新合并的令牌加入词汇表。<br>训练入口：train_bpe:</p>
<ol>
<li>使用多进程预分词文本文件。</li>
<li>迭代合并最高频字节对，直到词汇表达到指定大小（vocab_size）。</li>
<li>返回词汇表（vocab）和合并词（merges）。</li>
</ol>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">string = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">low low low low low &lt;|endoftext|&gt;</span></span><br><span class="line"><span class="string">lower lower widest widest widest &lt;|endoftext|&gt;</span></span><br><span class="line"><span class="string">newest newest newest newest newest newest </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">special_tokens = [<span class="string">&quot;&lt;|endoftext|&gt;&quot;</span>]</span><br><span class="line">PAT = <span class="string">r&quot;\S+&quot;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vocab, merge = train_bpe(vocab_size=<span class="number">269</span>)</span><br></pre></td></tr></table></figure>
<p>merge</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[(<span class="string">b&#x27;s&#x27;</span>, <span class="string">b&#x27;t&#x27;</span>),</span><br><span class="line"> (<span class="string">b&#x27;e&#x27;</span>, <span class="string">b&#x27;st&#x27;</span>),</span><br><span class="line"> (<span class="string">b&#x27;o&#x27;</span>, <span class="string">b&#x27;w&#x27;</span>),</span><br><span class="line"> (<span class="string">b&#x27;l&#x27;</span>, <span class="string">b&#x27;ow&#x27;</span>),</span><br><span class="line"> (<span class="string">b&#x27;w&#x27;</span>, <span class="string">b&#x27;est&#x27;</span>),</span><br><span class="line"> (<span class="string">b&#x27;n&#x27;</span>, <span class="string">b&#x27;e&#x27;</span>),</span><br><span class="line"> (<span class="string">b&#x27;ne&#x27;</span>, <span class="string">b&#x27;west&#x27;</span>),</span><br><span class="line"> (<span class="string">b&#x27;w&#x27;</span>, <span class="string">b&#x27;i&#x27;</span>),</span><br><span class="line"> (<span class="string">b&#x27;wi&#x27;</span>, <span class="string">b&#x27;d&#x27;</span>),</span><br><span class="line"> (<span class="string">b&#x27;wid&#x27;</span>, <span class="string">b&#x27;est&#x27;</span>),</span><br><span class="line"> (<span class="string">b&#x27;low&#x27;</span>, <span class="string">b&#x27;e&#x27;</span>),</span><br><span class="line"> (<span class="string">b&#x27;lowe&#x27;</span>, <span class="string">b&#x27;r&#x27;</span>)]</span><br></pre></td></tr></table></figure>
<h1 id="BPE-编码示例"><a href="#BPE-编码示例" class="headerlink" title="BPE 编码示例"></a>BPE 编码示例</h1><h2 id="输入与参数"><a href="#输入与参数" class="headerlink" title="输入与参数"></a>输入与参数</h2><ul>
<li><strong>输入字符串</strong>: <code>&#39;the cat ate&#39;</code></li>
<li><strong>词汇表</strong>:  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="number">0</span>: <span class="string">b&#x27; &#x27;</span>,   <span class="comment"># 空格</span></span><br><span class="line">    <span class="number">1</span>: <span class="string">b&#x27;a&#x27;</span>,   <span class="comment"># 字母 a</span></span><br><span class="line">    <span class="number">2</span>: <span class="string">b&#x27;c&#x27;</span>,   <span class="comment"># 字母 c</span></span><br><span class="line">    <span class="number">3</span>: <span class="string">b&#x27;e&#x27;</span>,   <span class="comment"># 字母 e</span></span><br><span class="line">    <span class="number">4</span>: <span class="string">b&#x27;h&#x27;</span>,   <span class="comment"># 字母 h</span></span><br><span class="line">    <span class="number">5</span>: <span class="string">b&#x27;t&#x27;</span>,   <span class="comment"># 字母 t</span></span><br><span class="line">    <span class="number">6</span>: <span class="string">b&#x27;th&#x27;</span>,  <span class="comment"># 序列 th</span></span><br><span class="line">    <span class="number">7</span>: <span class="string">b&#x27; c&#x27;</span>,  <span class="comment"># 空格+c</span></span><br><span class="line">    <span class="number">8</span>: <span class="string">b&#x27; a&#x27;</span>,  <span class="comment"># 空格+a</span></span><br><span class="line">    <span class="number">9</span>: <span class="string">b&#x27;the&#x27;</span>, <span class="comment"># 单词 the</span></span><br><span class="line">    <span class="number">10</span>: <span class="string">b&#x27;at&#x27;</span>  <span class="comment"># 序列 at</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><strong>合并规则</strong>:  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">    (<span class="string">b&#x27;t&#x27;</span>, <span class="string">b&#x27;h&#x27;</span>),   <span class="comment"># t 与 h 合并为 th</span></span><br><span class="line">    (<span class="string">b&#x27; &#x27;</span>, <span class="string">b&#x27;c&#x27;</span>),   <span class="comment"># 空格与 c 合并为 c</span></span><br><span class="line">    (<span class="string">b&#x27; &#x27;</span>, <span class="string">b&#x27;a&#x27;</span>),   <span class="comment"># 空格与 a 合并为 a</span></span><br><span class="line">    (<span class="string">b&#x27;th&#x27;</span>, <span class="string">b&#x27;e&#x27;</span>),  <span class="comment"># th 与 e 合并为 the</span></span><br><span class="line">    (<span class="string">b&#x27; a&#x27;</span>, <span class="string">b&#x27;t&#x27;</span>)   <span class="comment"># a 与 t 合并为 at</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="编码过程"><a href="#编码过程" class="headerlink" title="编码过程"></a>编码过程</h2><h3 id="1-预分词"><a href="#1-预分词" class="headerlink" title="1. 预分词"></a>1. 预分词</h3><p>输入字符串通过预分词器分割为：[‘the’, ‘ cat’, ‘ ate’]</p>
<h3 id="2-处理第一个预分词单元-‘the’"><a href="#2-处理第一个预分词单元-‘the’" class="headerlink" title="2. 处理第一个预分词单元 ‘the’"></a>2. 处理第一个预分词单元 ‘the’</h3><ul>
<li>初始字节表示：<code>[b&#39;t&#39;, b&#39;h&#39;, b&#39;e&#39;]</code></li>
<li>应用合并规则：<ol>
<li>匹配 <code>(b&#39;t&#39;, b&#39;h&#39;)</code> → 合并为 <code>[b&#39;th&#39;, b&#39;e&#39;]</code></li>
<li>匹配 <code>(b&#39;th&#39;, b&#39;e&#39;)</code> → 合并为 <code>[b&#39;the&#39;]</code></li>
</ol>
</li>
<li>无更多可应用规则，最终对应整数：<code>[9]</code></li>
</ul>
<h3 id="3-处理第二个预分词单元-‘-cat’"><a href="#3-处理第二个预分词单元-‘-cat’" class="headerlink" title="3. 处理第二个预分词单元 ‘ cat’"></a>3. 处理第二个预分词单元 ‘ cat’</h3><ul>
<li>初始字节表示：<code>[b&#39; &#39;, b&#39;c&#39;, b&#39;a&#39;, b&#39;t&#39;]</code>（注意空格保留）</li>
<li>应用合并规则：<ol>
<li>匹配 <code>(b&#39; &#39;, b&#39;c&#39;)</code> → 合并为 <code>[b&#39; c&#39;, b&#39;a&#39;, b&#39;t&#39;]</code></li>
<li>无其他可应用规则（需严格匹配连续字节对）</li>
</ol>
</li>
<li>最终对应整数序列：<code>[7, 1, 5]</code>（即 <code>b&#39; c&#39;</code>、<code>b&#39;a&#39;</code>、<code>b&#39;t&#39;</code>）</li>
</ul>
<h3 id="4-处理第三个预分词单元-‘-ate’"><a href="#4-处理第三个预分词单元-‘-ate’" class="headerlink" title="4. 处理第三个预分词单元 ‘ ate’"></a>4. 处理第三个预分词单元 ‘ ate’</h3><ul>
<li>初始字节表示：<code>[b&#39; &#39;, b&#39;a&#39;, b&#39;t&#39;, b&#39;e&#39;]</code></li>
<li>应用合并规则：<ol>
<li>匹配 <code>(b&#39; &#39;, b&#39;a&#39;)</code> → 合并为 <code>[b&#39; a&#39;, b&#39;t&#39;, b&#39;e&#39;]</code></li>
<li>匹配 <code>(b&#39; a&#39;, b&#39;t&#39;)</code> → 合并为 <code>[b&#39; at&#39;, b&#39;e&#39;]</code>（注意：此处规则中的 <code>b&#39; a&#39;</code> 是空格+a的合并结果）</li>
</ol>
</li>
<li>无更多可应用规则，最终对应整数序列：<code>[10, 3]</code>（即 <code>b&#39; at&#39;</code> 和 <code>b&#39;e&#39;</code>）</li>
</ul>
<h2 id="最终编码结果"><a href="#最终编码结果" class="headerlink" title="最终编码结果"></a>最终编码结果</h2><p>整数序列为：[9, 7, 1, 5, 10, 3]</p>
<h2 id="实现Tokenizer类"><a href="#实现Tokenizer类" class="headerlink" title="实现Tokenizer类"></a>实现Tokenizer类</h2><p><img src="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/497fe6cc2e43467b86a0d0b202ded271.png" class="lazyload" data-srcset="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/497fe6cc2e43467b86a0d0b202ded271.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="在这里插入图片描述"><br><img src="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/d53a2ab81a43447c8c60cc73697d7b7e.png" class="lazyload" data-srcset="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/d53a2ab81a43447c8c60cc73697d7b7e.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Tokenizer</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self, </span></span><br><span class="line"><span class="params">        vocab: <span class="type">Dict</span>[<span class="built_in">int</span>, <span class="built_in">bytes</span>],  <span class="comment"># 词汇表字典，将整数ID映射到字节token</span></span></span><br><span class="line"><span class="params">        merges: <span class="type">List</span>[<span class="type">Tuple</span>[<span class="built_in">bytes</span>, <span class="built_in">bytes</span>]],  <span class="comment"># BPE合并规则列表，每个元组表示要合并的两个字节序列</span></span></span><br><span class="line"><span class="params">        special_tokens: <span class="type">List</span>[<span class="built_in">str</span>] | <span class="literal">None</span> = []  <span class="comment"># 特殊token列表（如[CLS]、[SEP]等）</span></span></span><br><span class="line"><span class="params">    </span>):</span><br><span class="line">        self.vocab = vocab  <span class="comment"># 存储词汇表</span></span><br><span class="line">        self.merges = merges  <span class="comment"># 存储合并规则</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建反向词汇表，用于从字节token查找对应的整数ID</span></span><br><span class="line">        self.vocab_inv = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> self.vocab.items()&#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 处理特殊token</span></span><br><span class="line">        <span class="keyword">if</span> special_tokens <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            self.special_tokens = &#123;&#125;  <span class="comment"># 特殊token字典（token到ID的映射）</span></span><br><span class="line">            self.bytes_special_tokens = []  <span class="comment"># 特殊token的字节表示列表</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 为特殊token分配ID（从当前词汇表长度开始）</span></span><br><span class="line">            self.special_tokens = &#123;token: i <span class="keyword">for</span> i, token <span class="keyword">in</span> <span class="built_in">enumerate</span>(special_tokens, start=<span class="built_in">len</span>(self.vocab))&#125;</span><br><span class="line">            <span class="comment"># 将特殊token转换为字节表示</span></span><br><span class="line">            self.bytes_special_tokens = [token.encode(<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">for</span> token <span class="keyword">in</span> special_tokens <span class="keyword">if</span> <span class="built_in">isinstance</span>(token, <span class="built_in">str</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">register_special_tokens</span>(<span class="params">self, special_tokens</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;注册特殊token到词汇表中&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> special_tokens <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            self.special_tokens = &#123;&#125;</span><br><span class="line">            self.bytes_special_tokens = []</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 将字符串类型的特殊token转换为字节表示</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">all</span>(<span class="built_in">isinstance</span>(token, <span class="built_in">bytes</span>) <span class="keyword">for</span> token <span class="keyword">in</span> special_tokens):</span><br><span class="line">            bytes_special_tokens = [token.encode(<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">for</span> token <span class="keyword">in</span> special_tokens <span class="keyword">if</span> <span class="built_in">isinstance</span>(token, <span class="built_in">str</span>)]</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 将特殊token添加到词汇表中</span></span><br><span class="line">        <span class="keyword">for</span> i, token <span class="keyword">in</span> <span class="built_in">enumerate</span>(bytes_special_tokens, start=<span class="built_in">len</span>(self.vocab)):</span><br><span class="line">            self.vocab[i] = token  <span class="comment"># 将特殊token添加到词汇表</span></span><br><span class="line">            </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_pre_tokenize</span>(<span class="params">self, text</span>) -&gt; <span class="type">List</span>[<span class="built_in">bytes</span>]:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        预分词函数：将输入文本分割成字节token</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        参数:</span></span><br><span class="line"><span class="string">            text: 输入文本字符串</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        返回:</span></span><br><span class="line"><span class="string">            字节token列表</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 首先按特殊token分割文本</span></span><br><span class="line">        parts = split_by_special_tokens(text, <span class="built_in">list</span>(self.special_tokens.keys()))</span><br><span class="line">        token_list = []</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 处理每个分割部分</span></span><br><span class="line">        <span class="keyword">for</span> part <span class="keyword">in</span> parts:</span><br><span class="line">            <span class="keyword">if</span> part <span class="keyword">in</span> self.special_tokens.keys():</span><br><span class="line">                <span class="comment"># 如果是特殊token，直接编码为字节</span></span><br><span class="line">                token_list.append(part.encode(<span class="string">&quot;utf-8&quot;</span>))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 使用正则表达式分割普通文本</span></span><br><span class="line">                tokens = re.findall(PAT, part)</span><br><span class="line">                <span class="comment"># 将每个单词转换为字节表示</span></span><br><span class="line">                token_list.extend(word_to_bytes(token) <span class="keyword">for</span> token <span class="keyword">in</span> tokens)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> token_list</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">encode</span>(<span class="params">self, text: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;将文本编码为整数ID序列&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 预分词获取字节token</span></span><br><span class="line">        byte_tokens = self._pre_tokenize(text)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 将字节token转换为初始ID序列</span></span><br><span class="line">        token_ids = []</span><br><span class="line">        <span class="keyword">for</span> byte_token <span class="keyword">in</span> byte_tokens:</span><br><span class="line">            <span class="keyword">if</span> byte_token <span class="keyword">in</span> self.bytes_special_tokens:</span><br><span class="line">                <span class="comment"># 处理特殊token</span></span><br><span class="line">                token_ids.append([self.vocab_inv[byte_token]])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 将普通token拆分为单个字节并查找对应ID</span></span><br><span class="line">                token_ids.append([self.vocab_inv[b] <span class="keyword">for</span> b <span class="keyword">in</span> byte_token]) <span class="comment">#type: ignore</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 应用BPE合并规则</span></span><br><span class="line">        <span class="keyword">for</span> i, pretoken <span class="keyword">in</span> <span class="built_in">enumerate</span>(token_ids):</span><br><span class="line">            <span class="keyword">for</span> merge <span class="keyword">in</span> self.merges:</span><br><span class="line">                <span class="comment"># 检查合并后的token是否在词汇表中</span></span><br><span class="line">                new_index = self.vocab_inv.get(merge[<span class="number">0</span>] + merge[<span class="number">1</span>], <span class="literal">None</span>)</span><br><span class="line">                <span class="keyword">if</span> new_index <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># 尝试应用合并规则</span></span><br><span class="line">                merged = []</span><br><span class="line">                j = <span class="number">0</span></span><br><span class="line">                <span class="keyword">while</span> j &lt; <span class="built_in">len</span>(pretoken):</span><br><span class="line">                    <span class="keyword">if</span> (</span><br><span class="line">                        j &lt; <span class="built_in">len</span>(pretoken) - <span class="number">1</span></span><br><span class="line">                        <span class="keyword">and</span> (self.vocab[pretoken[j]], self.vocab[pretoken[j + <span class="number">1</span>]]) == merge</span><br><span class="line">                    ):</span><br><span class="line">                        <span class="comment"># 找到可合并的相邻token，应用合并</span></span><br><span class="line">                        merged.append(new_index)</span><br><span class="line">                        j += <span class="number">2</span>  <span class="comment"># 跳过已合并的token</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="comment"># 无法合并，保留原token</span></span><br><span class="line">                        merged.append(pretoken[j])</span><br><span class="line">                        j += <span class="number">1</span></span><br><span class="line">                        </span><br><span class="line">                pretoken = merged  <span class="comment"># 更新当前预分词序列</span></span><br><span class="line">            token_ids[i] = pretoken[:]  <span class="comment"># 保存处理后的序列</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 展平所有预分词序列并返回</span></span><br><span class="line">        <span class="keyword">return</span> [i <span class="keyword">for</span> pre <span class="keyword">in</span> token_ids <span class="keyword">for</span> i <span class="keyword">in</span> pre]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">encode_iterable</span>(<span class="params">self, iterable: Iterable[<span class="built_in">str</span>], batch_size: <span class="built_in">int</span> = <span class="number">1024</span></span>) -&gt; Iterator[<span class="built_in">int</span>]:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        批量编码可迭代对象中的文本行</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        参数:</span></span><br><span class="line"><span class="string">            iterable: 可迭代的文本行</span></span><br><span class="line"><span class="string">            batch_size: 批处理大小</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        返回:</span></span><br><span class="line"><span class="string">            整数ID的迭代器</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        batch = []</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> tqdm(iterable):</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> line:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            batch.append(line)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(batch) &gt;= batch_size:</span><br><span class="line">                <span class="comment"># 处理完整批次</span></span><br><span class="line">                <span class="keyword">for</span> encoded <span class="keyword">in</span> <span class="built_in">map</span>(self.encode, batch):</span><br><span class="line">                    <span class="keyword">yield</span> <span class="keyword">from</span> encoded  <span class="comment"># 逐个生成ID</span></span><br><span class="line">                batch.clear()  <span class="comment"># 清空批次</span></span><br><span class="line">                </span><br><span class="line">        <span class="comment"># 处理剩余的不完整批次</span></span><br><span class="line">        <span class="keyword">if</span> batch:</span><br><span class="line">            <span class="keyword">for</span> encoded <span class="keyword">in</span> <span class="built_in">map</span>(self.encode, batch):</span><br><span class="line">                <span class="keyword">yield</span> <span class="keyword">from</span> encoded</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">decode</span>(<span class="params">self, ids: <span class="built_in">list</span>[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        将整数ID序列解码回文本</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        参数:</span></span><br><span class="line"><span class="string">            ids: 整数ID列表</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        返回:</span></span><br><span class="line"><span class="string">            解码后的文本字符串</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 将ID转换回字节token，使用替换字符处理未知ID</span></span><br><span class="line">        tokens = <span class="string">b&quot;&quot;</span>.join(self.vocab.get(i, <span class="string">b&quot;\xef\xbf\xbd&quot;</span>) <span class="keyword">for</span> i <span class="keyword">in</span> ids)</span><br><span class="line">        <span class="comment"># 将字节解码为UTF-8字符串</span></span><br><span class="line">        <span class="keyword">return</span> tokens.decode(<span class="string">&quot;utf-8&quot;</span>, errors=<span class="string">&quot;replace&quot;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">from_files</span>(<span class="params"></span></span><br><span class="line"><span class="params">        cls, vocab_path: <span class="built_in">str</span>, merges_path: <span class="built_in">str</span>, special_tokens: <span class="built_in">list</span>[<span class="built_in">str</span>] | <span class="literal">None</span> = <span class="literal">None</span></span></span><br><span class="line"><span class="params">    </span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;从文件加载词汇表和合并规则创建Tokenizer实例&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 加载词汇表文件</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(vocab_path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> vf:</span><br><span class="line">            raw_vocab = pickle.load(vf)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 处理词汇表数据，确保值为字节类型</span></span><br><span class="line">        vocab = &#123;<span class="built_in">int</span>(k): (v.encode(<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">if</span> <span class="built_in">isinstance</span>(v, <span class="built_in">str</span>) <span class="keyword">else</span> v)</span><br><span class="line">                <span class="keyword">for</span> k, v <span class="keyword">in</span> raw_vocab.items()&#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 加载合并规则文件</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(merges_path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> mf:</span><br><span class="line">            raw_merges = pickle.load(mf)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 处理合并规则数据，确保为字节类型</span></span><br><span class="line">        merges = []</span><br><span class="line">        <span class="keyword">for</span> a, b <span class="keyword">in</span> raw_merges:</span><br><span class="line">            merges.append((</span><br><span class="line">                a.encode(<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">if</span> <span class="built_in">isinstance</span>(a, <span class="built_in">str</span>) <span class="keyword">else</span> a,</span><br><span class="line">                b.encode(<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">if</span> <span class="built_in">isinstance</span>(b, <span class="built_in">str</span>) <span class="keyword">else</span> b</span><br><span class="line">            ))</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 创建并返回Tokenizer实例</span></span><br><span class="line">        <span class="keyword">return</span> cls(vocab, merges, special_tokens)</span><br></pre></td></tr></table></figure>
<p><img src="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/81ada52024c24c5cbd8084c21f8abf5c.png" class="lazyload" data-srcset="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/81ada52024c24c5cbd8084c21f8abf5c.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="在这里插入图片描述"></p>
<h2 id="线性模型"><a href="#线性模型" class="headerlink" title="线性模型"></a>线性模型</h2><p>要自己设计一个线性模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Linear</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self, in_features: <span class="built_in">int</span>, out_features: <span class="built_in">int</span>, device= <span class="literal">None</span>, dtype = <span class="literal">None</span> </span></span><br><span class="line"><span class="params">    </span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        </span><br><span class="line">        self.in_features = in_features</span><br><span class="line">        self.out_features = out_features</span><br><span class="line">        </span><br><span class="line">        self.weight = nn.Parameter(torch.empty(in_features, out_features, device=device, dtype=dtype))</span><br><span class="line">        self._init_weight()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_init_weight</span>(<span class="params">self</span>):</span><br><span class="line">        std = (<span class="number">2</span> / (self.in_features + self.out_features)) ** <span class="number">0.5</span></span><br><span class="line">        nn.init.trunc_normal_(self.weight, mean=<span class="number">0.0</span>, std=std, a=-<span class="number">3</span> * std, b=<span class="number">3</span> * std)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="keyword">return</span> x @ self.weight</span><br></pre></td></tr></table></figure>
<p>设计一个Embedding层</p>
<p><img src="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/52f5b87299234e8e8dabc1feeef0898f.png" class="lazyload" data-srcset="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/52f5b87299234e8e8dabc1feeef0898f.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="在这里插入图片描述"><br><img src="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/765f4792e7cf4f3883c0615ee96ed51c.png" class="lazyload" data-srcset="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/765f4792e7cf4f3883c0615ee96ed51c.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="在这里插入图片描述"></p>
<h2 id="Transformer的嵌入层-Embedding"><a href="#Transformer的嵌入层-Embedding" class="headerlink" title="Transformer的嵌入层 Embedding"></a>Transformer的嵌入层 Embedding</h2><p>Transformer 的第一层是嵌入层，它将整数标记 ID 映射到维度为 d_model 的向量空间。文本序列被映射成词汇表的单词ID的数字序列。嵌入层再将每个数字序列射成一个嵌入向量，这是该词含义的一个更丰富的表示。<br>在这里我们将实现一个自定义的 Embedding 类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Embedding</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_embedding: <span class="built_in">int</span>, embedding_dim: <span class="built_in">int</span>, device = <span class="literal">None</span>, dtype = <span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        嵌入层初始化</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        参数:</span></span><br><span class="line"><span class="string">            num_embedding: int - 词表大小，即需要嵌入的不同token数量</span></span><br><span class="line"><span class="string">            embedding_dim: int - 嵌入向量的维度</span></span><br><span class="line"><span class="string">            device: torch.device - 计算设备 (CPU/GPU)</span></span><br><span class="line"><span class="string">            dtype: torch.dtype - 数据类型</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()  <span class="comment"># 调用父类nn.Module的初始化方法</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存参数</span></span><br><span class="line">        self.num_embedding = num_embedding  <span class="comment"># 词表大小</span></span><br><span class="line">        self.embedding_dim = embedding_dim  <span class="comment"># 嵌入维度</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 定义可学习的权重参数，形状为 (词表大小, 嵌入维度)</span></span><br><span class="line">        self.weight = nn.Parameter(</span><br><span class="line">            torch.empty(num_embedding, embedding_dim, device=device, dtype=dtype)</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># 初始化权重</span></span><br><span class="line">        self._init_weight()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_init_weight</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;使用截断正态分布初始化权重&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># trunc_normal_: 截断正态分布初始化，将值限制在[a, b]范围内</span></span><br><span class="line">        <span class="comment"># mean=0.0, std=1.0: 均值为0，标准差为1</span></span><br><span class="line">        <span class="comment"># a=-3.0, b=3.0: 将值限制在[-3, 3]标准差范围内，避免极端值</span></span><br><span class="line">        nn.init.trunc_normal_(self.weight, mean=<span class="number">0.0</span>, std=<span class="number">1.0</span>, a=-<span class="number">3.0</span>, b=<span class="number">3.0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, token_ids: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        前向传播过程</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        参数:</span></span><br><span class="line"><span class="string">            token_ids: torch.Tensor - 输入token索引，形状为 (B, S)</span></span><br><span class="line"><span class="string">                B: batch size (批大小)</span></span><br><span class="line"><span class="string">                S: sequence length (序列长度)</span></span><br><span class="line"><span class="string">                </span></span><br><span class="line"><span class="string">        返回:</span></span><br><span class="line"><span class="string">            torch.Tensor - 嵌入向量，形状为 (B, S, D)</span></span><br><span class="line"><span class="string">                D: embedding dimension (嵌入维度)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 使用索引查找：根据token_ids中的索引从weight中提取对应的嵌入向量</span></span><br><span class="line">        <span class="comment"># token_ids中的每个整数索引对应weight矩阵中的一行</span></span><br><span class="line">        <span class="comment"># 结果形状从 (B, S) 变为 (B, S, D)</span></span><br><span class="line">        <span class="keyword">return</span> self.weight[token_ids]</span><br></pre></td></tr></table></figure>
<p>每个 Transformer 块都包含两个子层：多头自注意力机制和位置感知前馈网络。<br>在最初的 Transformer 论文中，模型在每个子层周围使用了残差连接，然后进行层归一化。这种架构通常被称为“Post Norm” Transformer，因为层归一化是应用于子层输出的。</p>
<h2 id="前归一化"><a href="#前归一化" class="headerlink" title="前归一化"></a>前归一化</h2><p>然而，大量研究发现，&#x3D;&#x3D;将层归一化从每个子层的输出移到每个子层的输入可以提高 Transformer 的训练稳定性&#x3D;&#x3D;，下图展示了这种“前归一化”Transformer 块的视觉表示。然后，每个Transformer 块子层的输出通过残差连接加到子层输入上。前归一化的一个直观理解是，从输入嵌入到 Transformer 的最终输出之间存在一条干净的“残差流”，没有任何归一化，据称这有助于改善梯度流动。<br>这种预归一化 Transformer 现已成为当今语言模型（例如 GPT-3、LLaMA、PaLM 等）的标准，因此我们将实现这一变体。我们将依次介绍预归一化 Transformer 块的每个组件，并按顺序实现它们。<br><img src="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/f1b2f4af444f4116bf3ee0ddf34c7016.png" class="lazyload" data-srcset="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/f1b2f4af444f4116bf3ee0ddf34c7016.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="在这里插入图片描述"></p>
<h1 id="RMS-Layer-Normalization"><a href="#RMS-Layer-Normalization" class="headerlink" title="RMS Layer Normalization"></a>RMS Layer Normalization</h1><p><img src="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/895b60b9d311450cbed6ff26c5a60dc4.png" class="lazyload" data-srcset="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/895b60b9d311450cbed6ff26c5a60dc4.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RMSNorm</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model: <span class="built_in">int</span>, eps: <span class="built_in">float</span> = <span class="number">1e-5</span>, device=<span class="literal">None</span>, dtype=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        self.d_model = d_model</span><br><span class="line">        self.eps = eps</span><br><span class="line">        self.weight = nn.Parameter(torch.ones(d_model, device=device, dtype=dtype))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">        x = x.<span class="built_in">float</span>()  <span class="comment"># Ensure x is float for numerical stability</span></span><br><span class="line">        norm = torch.sqrt(torch.mean(x**<span class="number">2</span>, dim=-<span class="number">1</span>, keepdim=<span class="literal">True</span>) + self.eps)</span><br><span class="line">        normalized_x = x / norm</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> normalized_x * self.weight</span><br></pre></td></tr></table></figure>
<h2 id="SwiGLU"><a href="#SwiGLU" class="headerlink" title="SwiGLU"></a>SwiGLU</h2><p>把SiLU和GLU组合在一起就成为了SwiGLU<br><img src="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/33f943eab970499b86143ac79c652889.png" class="lazyload" data-srcset="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/33f943eab970499b86143ac79c652889.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="在这里插入图片描述"><br>先构建SiLu，再构建SwiGLU也就是FFN</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">SiLU</span>(<span class="params">x: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Swish activation function.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> x * torch.sigmoid(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FFN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model: <span class="built_in">int</span>, d_ff: <span class="built_in">int</span>, device=<span class="literal">None</span>, dtype=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.d_model = d_model</span><br><span class="line">        self.d_ff = d_ff</span><br><span class="line"></span><br><span class="line">        self.w1 = Linear(d_model, d_ff)</span><br><span class="line">        self.w2 = Linear(d_ff, d_model)</span><br><span class="line">        self.w3 = Linear(d_model, d_ff)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line"></span><br><span class="line">        output = self.w2(SiLU(self.w1(x)) * self.w3(x))</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<h2 id="RoPE旋转编码"><a href="#RoPE旋转编码" class="headerlink" title="RoPE旋转编码"></a>RoPE旋转编码</h2><p><img src="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/eb0771e0df5845d3a5ac51b78a260b8f.png" class="lazyload" data-srcset="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/eb0771e0df5845d3a5ac51b78a260b8f.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="在这里插入图片描述"><br>其作用就是为 Transformer 模型中的 token 嵌入注入位置信息，使得模型能够感知 token 在序列中的顺序（即“谁在前、谁在后”)，从而正确理解语言的结构和语义。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn </span><br><span class="line"></span><br><span class="line"><span class="comment"># einops 是一个用于张量操作的库，提供更清晰、更易读的张量重排语法</span></span><br><span class="line"><span class="keyword">import</span> einops</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RotaryPositionalEmbedding</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    旋转位置编码（Rotary Position Embedding, RoPE）模块。</span></span><br><span class="line"><span class="string">    与传统的绝对位置编码不同，RoPE 通过将位置信息编码为旋转矩阵，</span></span><br><span class="line"><span class="string">    使得注意力机制能够感知 token 之间的相对位置关系。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, theta: <span class="built_in">float</span>, d_k: <span class="built_in">float</span>, max_seq_len: <span class="built_in">int</span>, device=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        初始化 RoPE 模块。</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        参数:</span></span><br><span class="line"><span class="string">        - theta: 基础频率缩放因子（通常为 10000.0），控制频率衰减速度。</span></span><br><span class="line"><span class="string">        - d_k: 注意力头的维度（即每个 token 的嵌入维度）。</span></span><br><span class="line"><span class="string">        - max_seq_len: 支持的最大序列长度（用于预计算，但本实现中未显式使用）。</span></span><br><span class="line"><span class="string">        - device: 计算设备（如 &#x27;cuda&#x27; 或 &#x27;cpu&#x27;）。</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        </span><br><span class="line">        self.theta = theta</span><br><span class="line">        self.d_k = d_k</span><br><span class="line">        self.max_seq_len = max_seq_len</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 设置设备，默认为 CPU</span></span><br><span class="line">        self.device = device <span class="keyword">if</span> device <span class="keyword">else</span> torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算逆频率（inverse frequencies）：</span></span><br><span class="line">        <span class="comment"># 对于维度 0, 2, 4, ..., d_k-2，计算 1 / (theta^(i / d_k))</span></span><br><span class="line">        <span class="comment"># 这些频率用于构建旋转角度</span></span><br><span class="line">        <span class="comment"># torch.arange(0, d_k, 2) 生成 [0, 2, 4, ..., d_k-2]（假设 d_k 为偶数）</span></span><br><span class="line">        inv_freq = <span class="number">1.0</span> / (self.theta ** (torch.arange(<span class="number">0</span>, d_k, <span class="number">2</span>).<span class="built_in">float</span>() / d_k))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 使用 register_buffer 注册为非参数缓冲区（不会被优化器更新，但会随模型移动设备）</span></span><br><span class="line">        self.register_buffer(<span class="string">&quot;inv_freq&quot;</span>, inv_freq)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_rotate_half</span>(<span class="params">self, x: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        对输入张量进行“旋转一半”操作：</span></span><br><span class="line"><span class="string">        将最后一维分成两半，交换并取负，实现 90 度旋转。</span></span><br><span class="line"><span class="string">        例如：[x1, x2, x3, x4] -&gt; [-x2, x1, -x4, x3]</span></span><br><span class="line"><span class="string">        这是 RoPE 的核心操作，用于实现复数乘法的实部形式。</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        参数:</span></span><br><span class="line"><span class="string">        - x: 形状为 [..., d_k] 的张量</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        返回:</span></span><br><span class="line"><span class="string">        - 旋转后的张量，形状与输入相同</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 将最后一维按每2个元素分组：(..., d_k) -&gt; (..., d_k//2, 2)</span></span><br><span class="line">        x = einops.rearrange(x, <span class="string">&quot;... (d r) -&gt; ... d r&quot;</span>, r=<span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 拆分为两部分：x1 是偶数索引部分，x2 是奇数索引部分</span></span><br><span class="line">        x1, x2 = x.unbind(dim=-<span class="number">1</span>)  <span class="comment"># x1: [..., d_k//2], x2: [..., d_k//2]</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 构造旋转后的形式：(-x2, x1)</span></span><br><span class="line">        x = torch.stack((-x2, x1), dim=-<span class="number">1</span>)  <span class="comment"># [..., d_k//2, 2]</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 重新合并为 [..., d_k]</span></span><br><span class="line">        <span class="keyword">return</span> einops.rearrange(x, <span class="string">&quot;... d r -&gt; ... (d r)&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x: torch.Tensor, token_positions: torch.Tensor</span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        应用旋转位置编码到输入张量。</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        RoPE 的数学本质是：将 token 嵌入视为复数，然后乘以 e^&#123;i * m * θ&#125;（m 是位置，θ 是频率），</span></span><br><span class="line"><span class="string">        等价于：x * cos(mθ) + rotate(x) * sin(mθ)</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        参数:</span></span><br><span class="line"><span class="string">        - x: 输入张量，形状 [..., seq_len, d_k]</span></span><br><span class="line"><span class="string">        - token_positions: 位置索引张量，形状 [..., seq_len]，</span></span><br><span class="line"><span class="string">          通常为 [0, 1, 2, ..., seq_len-1]，支持动态位置（如滑动窗口）</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        返回:</span></span><br><span class="line"><span class="string">        - 应用 RoPE 后的张量，形状与 x 相同</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        seq_len = x.size(-<span class="number">2</span>)  <span class="comment"># 获取序列长度</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果未提供 token_positions，则自动生成从 0 到 seq_len-1 的位置索引</span></span><br><span class="line">        <span class="keyword">if</span> token_positions <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            token_positions = torch.arange(seq_len, device=x.device)</span><br><span class="line">            <span class="comment"># 扩展为与 batch 维度对齐：(seq_len,) -&gt; (B, seq_len)</span></span><br><span class="line">            token_positions = token_positions.unsqueeze(<span class="number">0</span>).expand(x.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算每个位置和每个频率维度的旋转角度 θ = m * inv_freq</span></span><br><span class="line">        <span class="comment"># token_positions: [..., seq_len]</span></span><br><span class="line">        <span class="comment"># inv_freq: [d_k // 2]</span></span><br><span class="line">        <span class="comment"># 结果 theta: [..., seq_len, d_k // 2]</span></span><br><span class="line">        theta = torch.einsum(<span class="string">&quot;... n, d -&gt; ... n d&quot;</span>, token_positions, self.inv_freq)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算 cos(θ) 和 sin(θ)，并重复每个值两次以匹配 d_k 维度</span></span><br><span class="line">        <span class="comment"># 例如：[cos0, cos1] -&gt; [cos0, cos0, cos1, cos1]</span></span><br><span class="line">        cos = theta.cos().repeat_interleave(<span class="number">2</span>, dim=-<span class="number">1</span>)  <span class="comment"># [..., seq_len, d_k]</span></span><br><span class="line">        sin = theta.sin().repeat_interleave(<span class="number">2</span>, dim=-<span class="number">1</span>)  <span class="comment"># [..., seq_len, d_k]</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 应用 RoPE 公式：x_rot = x * cos + rotate_half(x) * sin</span></span><br><span class="line">        <span class="comment"># 这等价于复数乘法：(x_real + i*x_imag) * (cos + i*sin)</span></span><br><span class="line">        x = x * cos + self._rotate_half(x) * sin</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<h2 id="Softmax"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax</h2><p><img src="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/5f3d5c3ab90e493abfb0b89ebd329746.png" class="lazyload" data-srcset="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/5f3d5c3ab90e493abfb0b89ebd329746.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="在这里插入图片描述"><br>Softmax 将这注意力得分转换为 <strong>非负、和为1 的权重</strong>：<br><img src="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/0bcdd5afa6944cb2b981997ac2d43007.png" class="lazyload" data-srcset="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/0bcdd5afa6944cb2b981997ac2d43007.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">softmax</span>(<span class="params">x: torch.Tensor, dim: <span class="built_in">int</span> = -<span class="number">1</span></span>) -&gt; torch.Tensor:</span><br><span class="line">    x = x - torch.<span class="built_in">max</span>(x, dim=dim, keepdim=<span class="literal">True</span>).values</span><br><span class="line">    x = torch.exp(x)</span><br><span class="line">    x = x / torch.<span class="built_in">sum</span>(x, dim=dim, keepdim=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<h2 id="SDPA"><a href="#SDPA" class="headerlink" title="SDPA"></a>SDPA</h2><p>SDPA实现标准的缩放点积注意力机制，根据查询（q）与键（k）的相似度，动态地从值（v）中提取加权信息，并支持通过 mask 控制注意力范围，重点读value，忽略不重要的部分。<br>SDPA就是这个计算：<br><img src="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/62e35620e5df4d7f90bff891f74fdc0a.png" class="lazyload" data-srcset="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/62e35620e5df4d7f90bff891f74fdc0a.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="在这里插入图片描述"></p>
<p><img src="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/d865f38cb5684e83a6b84dc16fbaf224.png" class="lazyload" data-srcset="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/d865f38cb5684e83a6b84dc16fbaf224.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="在这里插入图片描述"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">scaled_dot_product_attention</span>(<span class="params">q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, mask: torch.Tensor | <span class="literal">None</span> = <span class="literal">None</span></span>) -&gt; torch.Tensor:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    q: (B, S_q, D)</span></span><br><span class="line"><span class="string">    k: (B, S_k, D)</span></span><br><span class="line"><span class="string">    v: (B, S_v, D)</span></span><br><span class="line"><span class="string">    mask: (B, S_q, S_k) or None</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    d_k = k.size(-<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    scores = torch.matmul(q, k.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) / (d_k ** <span class="number">0.5</span>)  <span class="comment"># (B, S_q, S_k)</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        scores = scores.masked_fill(mask == <span class="number">0</span>, <span class="built_in">float</span>(<span class="string">&#x27;-inf&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    attn_weights = softmax(scores, dim=-<span class="number">1</span>)  <span class="comment"># (B, S_q, S_k)</span></span><br><span class="line">    </span><br><span class="line">    output = torch.matmul(attn_weights, v)  <span class="comment"># (B, S_q, D)</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>

<p>输出的结果是每个查询位置得到一个融合了上下文信息的表示</p>
<h1 id="多头自注意力"><a href="#多头自注意力" class="headerlink" title="多头自注意力"></a>多头自注意力</h1><p><img src="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/59bb86df06b2481386c23bd7aa37cb34.png" class="lazyload" data-srcset="https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/59bb86df06b2481386c23bd7aa37cb34.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="在这里插入图片描述"><br>这里的qkv虽然看起来一样，但是在nn.Linear中其Wq，Wk，Wv权重矩阵是完全不同的。<br>1.多头（Multi-Head）<br>把注意力拆成多个“小组”，每个小组独立关注不同的信息模式（比如一个头关注语法，一个头关注语义），最后汇总，效果比单头强得多。<br>2.位置感知（RoPE）<br>如果启用了<code>use_rope=True</code>，模型就能知道“第一个词”、“第二个词”……的位置关系，而且这种位置编码对长序列更友好（比传统的加性位置编码更强）。<br>3.防止作弊（因果掩码）<br>在生成文本时（比如写句子），模型只能看到当前词及之前的词，不能偷看未来的词。<code>_causal_mask</code> 就是干这个的——像考试时遮住后面的题目。<br>4.端到端学习<br>所有投影层（q_proj, k_proj 等)都是可训练的，模型会自动学会如何提取最有用的查询、键、值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MultiHeadAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        d_model: <span class="built_in">int</span>,                  <span class="comment"># 模型的隐藏层维度（例如 512）</span></span></span><br><span class="line"><span class="params">        num_heads: <span class="built_in">int</span>,                <span class="comment"># 注意力头的数量（例如 8）</span></span></span><br><span class="line"><span class="params">        use_rope: <span class="built_in">bool</span> = <span class="literal">False</span>,        <span class="comment"># 是否使用旋转位置编码（RoPE）</span></span></span><br><span class="line"><span class="params">        max_seq_len: <span class="built_in">int</span> | <span class="literal">None</span> = <span class="literal">None</span>, <span class="comment"># 最大序列长度（用于 RoPE 缓存）</span></span></span><br><span class="line"><span class="params">        theta: <span class="built_in">float</span> | <span class="literal">None</span> = <span class="literal">None</span>,     <span class="comment"># RoPE 的基底参数（通常为 10000.0）</span></span></span><br><span class="line"><span class="params">        token_positions: torch.Tensor | <span class="literal">None</span> = <span class="literal">None</span>,  <span class="comment"># 显式指定每个 token 的位置（用于 RoPE）</span></span></span><br><span class="line"><span class="params">    </span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        </span><br><span class="line">        self.d_model = d_model</span><br><span class="line">        self.num_heads = num_heads</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 检查 d_model 是否能被 num_heads 整除：每个头必须分到整数维度</span></span><br><span class="line">        <span class="keyword">if</span> d_model % num_heads != <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;d_model must be divisible by num_heads&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        self.head_dim = d_model // num_heads  <span class="comment"># 每个注意力头的维度</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># RoPE 相关配置</span></span><br><span class="line">        self.use_rope = use_rope</span><br><span class="line">        self.max_seq_len = max_seq_len</span><br><span class="line">        self.theta = theta</span><br><span class="line">        self.token_positions = token_positions</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果启用 RoPE 且提供了必要参数，则初始化 RoPE 模块</span></span><br><span class="line">        <span class="keyword">if</span> use_rope <span class="keyword">and</span> (max_seq_len <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> theta <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>):</span><br><span class="line">            <span class="comment"># 注意：RoPE 通常作用于每个头的 head_dim 维度</span></span><br><span class="line">            self.rope = RotaryPositionalEmbedding(theta, self.head_dim, max_seq_len)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 线性投影层：将输入分别映射为 Query、Key、Value</span></span><br><span class="line">        self.q_proj = nn.Linear(d_model, d_model)  <span class="comment"># 生成 Q</span></span><br><span class="line">        self.k_proj = nn.Linear(d_model, d_model)  <span class="comment"># 生成 K</span></span><br><span class="line">        self.v_proj = nn.Linear(d_model, d_model)  <span class="comment"># 生成 V</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 输出投影层：将多头拼接后的结果映射回 d_model 维度</span></span><br><span class="line">        self.out_proj = nn.Linear(d_model, d_model)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_causal_mask</span>(<span class="params">self, seq_len: <span class="built_in">int</span></span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        生成因果掩码（Causal Mask），用于自回归生成（如语言模型）。</span></span><br><span class="line"><span class="string">        只允许每个位置关注它自己及之前的位置，不能看未来。</span></span><br><span class="line"><span class="string">        返回形状: (1, 1, seq_len, seq_len)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># torch.tril 保留下三角（包括对角线），上三角为 0</span></span><br><span class="line">        mask = torch.tril(torch.ones(seq_len, seq_len)).<span class="built_in">bool</span>()  <span class="comment"># (S, S)</span></span><br><span class="line">        <span class="comment"># 增加 batch 和 head 维度以适配 attention 输入：(1, 1, S, S)</span></span><br><span class="line">        mask = mask.unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> mask</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, in_features: torch.Tensor</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        前向传播：实现多头注意力计算。</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        参数:</span></span><br><span class="line"><span class="string">            in_features: 输入特征，形状 (B, S, D)</span></span><br><span class="line"><span class="string">                B = batch size</span></span><br><span class="line"><span class="string">                S = sequence length</span></span><br><span class="line"><span class="string">                D = d_model（模型维度）</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        返回:</span></span><br><span class="line"><span class="string">            output: 注意力输出，形状 (B, S, D)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        B, S, D = in_features.size()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 1. 线性投影 + 拆分为多头</span></span><br><span class="line">        <span class="comment"># 先投影到 d_model，再 reshape 成 (B, S, num_heads, head_dim)</span></span><br><span class="line">        <span class="comment"># 然后转置为 (B, num_heads, S, head_dim)，便于后续矩阵运算</span></span><br><span class="line">        q = self.q_proj(in_features).view(B, S, self.num_heads, self.head_dim).transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># (B, H, S, D/H)</span></span><br><span class="line">        k = self.k_proj(in_features).view(B, S, self.num_heads, self.head_dim).transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># (B, H, S, D/H)</span></span><br><span class="line">        v = self.v_proj(in_features).view(B, S, self.num_heads, self.head_dim).transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># (B, H, S, D/H)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2. （可选）应用旋转位置编码（RoPE）为了保留词汇的相对位置关系</span></span><br><span class="line">        <span class="keyword">if</span> self.use_rope:</span><br><span class="line">            <span class="comment"># RoPE 将位置信息通过旋转矩阵融入 q 和 k，保留相对位置关系</span></span><br><span class="line">            q = self.rope(q, self.token_positions)  <span class="comment"># token_positions 可为 None，此时默认使用 0,1,2,...</span></span><br><span class="line">            k = self.rope(k, self.token_positions)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 3. 生成因果掩码（用于解码器或自回归任务）防止模型看到未来的数据</span></span><br><span class="line">        mask = self._causal_mask(S) </span><br><span class="line">        mask = mask.to(q.device)  <span class="comment"># 确保 mask 与数据在同一设备（CPU/GPU）</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 4. 调用缩放点积注意力（注意：此处假设 scaled_dot_product_attention 支持 (B, H, S_q, S_k) 输入）</span></span><br><span class="line">        <span class="comment"># 输出形状: (B, H, S, D/H)</span></span><br><span class="line">        attn_output = scaled_dot_product_attention(q, k, v, mask)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 5. 合并多头：转置回 (B, S, H, D/H) → reshape 为 (B, S, D)</span></span><br><span class="line">        attn_output = attn_output.transpose(<span class="number">1</span>, <span class="number">2</span>).contiguous().view(B, S, D)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 6. 最终线性投影</span></span><br><span class="line">        output = self.out_proj(attn_output)  <span class="comment"># (B, S, D)</span></span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<p>output是每个词（或 token）在“看过整个句子（或允许看的部分）之后”，重新生成的、带有上下文信息的新表示。</p>

  </div>
  
  
    
    <div class='footer'>
       <!-- 参考资料、相关资料等 -->
      
       <!-- 相关文章 -->
      
      <!-- 版权声明组件 -->
      
        
          <div class='copyright'>
            <blockquote>
              
                
                  <p>博客内容遵循 署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议</p>

                
              
                
                  <p>本文永久链接是：<a href="https://mengfanjun020906.github.io/2025/10/02/Stanford CS336 assignment1（上）/">https://mengfanjun020906.github.io/2025/10/02/Stanford CS336 assignment1（上）/</a></p>
                
              
            </blockquote>
          </div>
        
      
      <!-- 打赏组件 -->
      
    </div>
  
  
    


  <div class='article-meta' id="bottom">
    <div class='new-meta-box'>
      
        
          <div class="new-meta-item date" itemprop="dateModified" datetime="2025-12-12T22:25:39+08:00">
  <a class='notlink'>
    <i class="fa-solid fa-edit fa-fw" aria-hidden="true"></i>
    <p>更新于：Dec 12, 2025</p>
  </a>
</div>

        
      
        
          
  
  <div class="new-meta-item meta-tags"><a class="tag" href="/tags/%E5%AD%A6%E4%B9%A0/" rel="nofollow"><i class="fa-solid fa-hashtag fa-fw" aria-hidden="true"></i><p>学习</p></a></div> <div class="new-meta-item meta-tags"><a class="tag" href="/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/" rel="nofollow"><i class="fa-solid fa-hashtag fa-fw" aria-hidden="true"></i><p>大模型</p></a></div>
  <span hidden itemprop="keywords">学习 大模型</span>


        
      
        
          
  <div class="new-meta-item share -mob-share-list">
  <div class="-mob-share-list share-body">
    
      
        <a class="-mob-share-qq" title="" rel="external nofollow noopener noreferrer noopener"
          
          target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=https://mengfanjun020906.github.io/2025/10/02/Stanford%20CS336%20assignment1%EF%BC%88%E4%B8%8A%EF%BC%89/&title=Stanford CS336 assignment1（上） - MengFanjun的博客&summary="
          
          >
          
            <img src="https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/logo/128/qq.png" class="lazyload" data-srcset="https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/logo/128/qq.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
          
        </a>
      
    
      
        <a class="-mob-share-qzone" title="" rel="external nofollow noopener noreferrer noopener"
          
          target="_blank" href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=https://mengfanjun020906.github.io/2025/10/02/Stanford%20CS336%20assignment1%EF%BC%88%E4%B8%8A%EF%BC%89/&title=Stanford CS336 assignment1（上） - MengFanjun的博客&summary="
          
          >
          
            <img src="https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/logo/128/qzone.png" class="lazyload" data-srcset="https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/logo/128/qzone.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
          
        </a>
      
    
      
        <a class="-mob-share-weibo" title="" rel="external nofollow noopener noreferrer noopener"
          
          target="_blank" href="http://service.weibo.com/share/share.php?url=https://mengfanjun020906.github.io/2025/10/02/Stanford%20CS336%20assignment1%EF%BC%88%E4%B8%8A%EF%BC%89/&title=Stanford CS336 assignment1（上） - MengFanjun的博客&summary="
          
          >
          
            <img src="https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/logo/128/weibo.png" class="lazyload" data-srcset="https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/logo/128/weibo.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
          
        </a>
      
    
      
    
      
    
  </div>
</div>



        
      
    </div>
    <!-- Custom Files bottomMeta begin -->
    
    <!-- Custom Files bottomMeta end -->
  </div>


  
  

  
    <div class="prev-next">
      
        <a class='prev' href='/2025/12/06/Qwen3-8B%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E5%AE%9E%E6%88%98/'>
          <p class='title'><i class="fa-solid fa-chevron-left" aria-hidden="true"></i>Qwen3-8B大模型微调实战</p>
          <p class='content'>安装相关依赖12345678910!pip install unsloth# 卸载当前已安装的 unsloth 包（如果已安装），然后从 GitHub 的源代码安装最新版本。# 这样可以确保我们...</p>
        </a>
      
      
        <a class='next' href='/2025/08/30/Standford%20CS336%EF%BC%88%E4%BA%8C%EF%BC%89%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/'>
          <p class='title'>Standford CS336（二）训练模型介绍<i class="fa-solid fa-chevron-right" aria-hidden="true"></i></p>
          <p class='content'>github库链接：https://github.com/stanford-cs336/spring2025-lectures
概述本讲将讨论训练模型所需的所有基本要素，从张量到底层模型，再到优...</p>
        </a>
      
    </div>
  
  <!-- Custom Files postEnd begin-->
  
  <!-- Custom Files postEnd end-->
</article>


  


  <article class="post white-box shadow floatable blur" id="comments">
    <span hidden>
      <meta itemprop="discussionUrl" content="/2025/10/02/Stanford%20CS336%20assignment1%EF%BC%88%E4%B8%8A%EF%BC%89/index.html#comments">
    </span>
    <p ct><i class='fa-solid fa-comments'></i> 评论</p>
    

    <div id="layoutHelper-comments"></div>

  </article>






</div>
<aside id='l_side' itemscope itemtype="http://schema.org/WPSideBar">
  

  
    
    
      
    
  


<div class="widget-sticky pjax">

  
  


  <section class="widget toc-wrapper desktop mobile " id="toc-div" >
    
  <header>
    
      <i class="fa-solid fa-list fa-fw" aria-hidden="true"></i><span class='name'>本文目录</span>
    
  </header>


    <div class='content'>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#The-Unicode-Standard"><span class="toc-text">The Unicode Standard</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%AD%E6%96%99%E5%BA%93%E6%96%87%E6%9C%AC"><span class="toc-text">语料库文本</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%8D%E6%B1%87%E8%A1%A8%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-text">词汇表初始化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%84%E5%88%86%E8%AF%8D"><span class="toc-text">预分词</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%88%E5%B9%B6%E8%BF%87%E7%A8%8B"><span class="toc-text">合并过程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E8%BD%AE%E5%90%88%E5%B9%B6"><span class="toc-text">第一轮合并</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E8%BD%AE%E5%90%88%E5%B9%B6"><span class="toc-text">第二轮合并</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%8E%E7%BB%AD%E5%90%88%E5%B9%B6"><span class="toc-text">后续合并</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%88%E5%B9%B66%E6%AC%A1%E5%90%8E%E7%9A%84%E8%AF%8D%E6%B1%87%E8%A1%A8"><span class="toc-text">合并6次后的词汇表</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BE%93%E5%85%A5%E4%B8%8E%E5%8F%82%E6%95%B0"><span class="toc-text">输入与参数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BC%96%E7%A0%81%E8%BF%87%E7%A8%8B"><span class="toc-text">编码过程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E9%A2%84%E5%88%86%E8%AF%8D"><span class="toc-text">1. 预分词</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%A4%84%E7%90%86%E7%AC%AC%E4%B8%80%E4%B8%AA%E9%A2%84%E5%88%86%E8%AF%8D%E5%8D%95%E5%85%83-%E2%80%98the%E2%80%99"><span class="toc-text">2. 处理第一个预分词单元 ‘the’</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%A4%84%E7%90%86%E7%AC%AC%E4%BA%8C%E4%B8%AA%E9%A2%84%E5%88%86%E8%AF%8D%E5%8D%95%E5%85%83-%E2%80%98-cat%E2%80%99"><span class="toc-text">3. 处理第二个预分词单元 ‘ cat’</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%A4%84%E7%90%86%E7%AC%AC%E4%B8%89%E4%B8%AA%E9%A2%84%E5%88%86%E8%AF%8D%E5%8D%95%E5%85%83-%E2%80%98-ate%E2%80%99"><span class="toc-text">4. 处理第三个预分词单元 ‘ ate’</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%80%E7%BB%88%E7%BC%96%E7%A0%81%E7%BB%93%E6%9E%9C"><span class="toc-text">最终编码结果</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0Tokenizer%E7%B1%BB"><span class="toc-text">实现Tokenizer类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B"><span class="toc-text">线性模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Transformer%E7%9A%84%E5%B5%8C%E5%85%A5%E5%B1%82-Embedding"><span class="toc-text">Transformer的嵌入层 Embedding</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E5%BD%92%E4%B8%80%E5%8C%96"><span class="toc-text">前归一化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SwiGLU"><span class="toc-text">SwiGLU</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RoPE%E6%97%8B%E8%BD%AC%E7%BC%96%E7%A0%81"><span class="toc-text">RoPE旋转编码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Softmax"><span class="toc-text">Softmax</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SDPA"><span class="toc-text">SDPA</span></a></li></ol>
    </div>
  </section>

  

</div>


<!-- 没有 pjax 占位会报错 万恶的 pjax -->

  <div class="pjax">
    <!-- pjax占位 -->
  </div>

  <div class="pjax">
    <!-- pjax占位 -->
  </div>

  <div class="pjax">
    <!-- pjax占位 -->
  </div>

  <div class="pjax">
    <!-- pjax占位 -->
  </div>

  <div class="pjax">
    <!-- pjax占位 -->
  </div>

  <div class="pjax">
    <!-- pjax占位 -->
  </div>

  <div class="pjax">
    <!-- pjax占位 -->
  </div>

  <div class="pjax">
    <!-- pjax占位 -->
  </div>

  <div class="pjax">
    <!-- pjax占位 -->
  </div>

  <div class="pjax">
    <!-- pjax占位 -->
  </div>

  <!-- Custom Files side begin -->
  
  <!-- Custom Files side end -->
</aside>



          <!--此文件用来存放一些不方便取值的变量-->
<!--思路大概是将值藏到重加载的区域内-->

<pjax>
<script>
  window.pdata={}
  pdata.ispage=true;
  pdata.commentPath="";
  pdata.commentPlaceholder="";
  pdata.commentConfig={};
  //  see: /layout/_partial/scripts/_ctrl/coverCtrl.ejs
  
    // header
    var l_header=document.getElementById("l_header");
    
    l_header.classList.remove("show");
    
    
      // cover
      var cover_wrapper=document.querySelector('#l_cover .cover-wrapper');
      var scroll_down=document.getElementById('scroll-down');
      cover_wrapper.id="half";
      cover_wrapper.style.display="";
      scroll_down.style.display="none";
    
  
</script>
</pjax>
        </div>
        
  
  <footer class="footer clearfix"  itemscope itemtype="http://schema.org/WPFooter">
    <br><br>
    
      
        <div class="aplayer-container">
          

  
    <meting-js
      theme='#1BCDFC'
      autoplay='true'
      volume='0.7'
      loop='all'
      order='list'
      fixed='true'
      list-max-height='320px'
      server='netease'
      type='playlist'
      id='993524571'
      list-folded='true'>
    </meting-js>
  


        </div>
      
    
      
        <br>
        <div class="social-wrapper" itemprop="about" itemscope itemtype="http://schema.org/Thing">
          
            
              <a href="mailto:mengfanjun_020906@outlook.com"
                class="social fas fa-envelope flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer" itemprop="url">
                
              </a>
            
          
            
              <a href="https://github.com/MengFanjun020906"
                class="social fab fa-github flat-btn"
                target="_blank"
                rel="external nofollow noopener noreferrer" itemprop="url">
                
              </a>
            
          
        </div>
      
    
      
        <div><p>Blog content follows the <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en">Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License</a></p>
</div>
      
    
      
        Use
        <a href="https://github.com/volantis-x/hexo-theme-volantis/#5.7.7" target="_blank" class="codename">Volantis</a>
        as theme, total visits
          <span id="busuanzi_value_site_pv"><i class="fa-solid fa-loader fa-spin fa-fw" aria-hidden="true"></i></span>
          times
        
      
    
      
        <div class='copyright'>
        <p><a href="/">Copyright © 2022-2023 孟凡钧</a></p>

        </div>
      
    
    <!-- Custom Files footer begin-->
    
    <!-- Custom Files footer end-->
  </footer>


        <a id="s-top" class="fa-solid fa-arrow-up fa-fw" href="/" onclick="return false;" title="top"></a>
      </div>
    </div>
    <div>
      <script>
  /******************** volantis.dom ********************************/
  // 页面选择器 将dom对象缓存起来 see: /source/js/app.js etc.
  volantis.dom.bodyAnchor = volantis.dom.$(document.getElementById("safearea")); // 页面主体
  volantis.dom.topBtn = volantis.dom.$(document.getElementById('s-top')); // 向上
  volantis.dom.wrapper = volantis.dom.$(document.getElementById('wrapper')); // 整个导航栏
  volantis.dom.coverAnchor = volantis.dom.$(document.querySelector('#l_cover .cover-wrapper')); // 1个
  volantis.dom.switcher = volantis.dom.$(document.querySelector('#l_header .switcher .s-search')); // 搜索按钮   移动端 1个
  volantis.dom.header = volantis.dom.$(document.getElementById('l_header')); // 移动端导航栏
  volantis.dom.search = volantis.dom.$(document.querySelector('#l_header .m_search')); // 搜索框 桌面端 移动端 1个
  volantis.dom.mPhoneList = volantis.dom.$(document.querySelectorAll('#l_header .m-phone .list-v')); //  手机端 子菜单 多个
</script>

<script>
  
  volantis.css("https://unpkg.com/volantis-static@0.0.1654736714924/libs/@fortawesome/fontawesome-free/css/all.min.css");
  
  
  
</script>
<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=bPcCRxC4bZtkgRsg7UgdnDBMTDZWpbJMNpbRzeeUhkQ">
</script>
<!-- required -->


<!-- internal -->

<script src="/js/app.js"></script>






<!-- rightmenu要在darkmode之前（ToggleButton） darkmode要在comments之前（volantis.dark.push）-->



<script>
  function loadIssuesJS() {
    
      const sites_api = document.getElementById('sites-api');
      if (sites_api != undefined && typeof SitesJS === 'undefined') {
        volantis.js("/js/plugins/tags/sites.js")
      }
    
    
      const friends_api = document.getElementById('friends-api');
      if (friends_api != undefined && typeof FriendsJS === 'undefined') {
        volantis.js("/js/plugins/tags/friends.js")
      }
    
    
      const contributors_api = document.getElementById('contributors-api');
      if (contributors_api != undefined && typeof ContributorsJS === 'undefined') {
        volantis.js("/js/plugins/tags/contributors.js")
      }
    
  };
  loadIssuesJS()
  volantis.pjax.push(()=>{
    loadIssuesJS();
  })

</script>




  <script defer src="https://unpkg.com/volantis-static@0.0.1654736714924/libs/vanilla-lazyload/dist/lazyload.min.js"></script>
<script>
  // https://www.npmjs.com/package/vanilla-lazyload
  // Set the options globally
  // to make LazyLoad self-initialize
  window.lazyLoadOptions = {
    elements_selector: ".lazyload",
    threshold: 0
  };
  // Listen to the initialization event
  // and get the instance of LazyLoad
  window.addEventListener(
    "LazyLoad::Initialized",
    function (event) {
      window.lazyLoadInstance = event.detail.instance;
    },
    false
  );
  document.addEventListener('DOMContentLoaded', function () {
    lazyLoadInstance.update();
  });
  document.addEventListener('pjax:complete', function () {
    lazyLoadInstance.update();
  });
</script>




  

<script>
  window.FPConfig = {
	delay: 0,
	ignoreKeywords: ["#"],
	maxRPS: 6,
	hoverDelay: 0
  };
</script>
<script defer src="https://unpkg.com/volantis-static@0.0.1654736714924/libs/flying-pages/flying-pages.min.js"></script>







  <script>
  volantis.css("https://unpkg.com/volantis-static@0.0.1654736714924/libs/aplayer/dist/APlayer.min.css");
  (async () => {
    // APlayer 需要在  MetingJS 之前加载
    await volantis.js("https://unpkg.com/volantis-static@0.0.1654736714924/libs/aplayer/dist/APlayer.min.js")
    await volantis.js("https://unpkg.com/volantis-static@0.0.1654736714924/libs/meting/dist/Meting.min.js")
  
  })();

  function SetAPlayerPlugin(){
    let Metings = document.querySelectorAll('meting-js');
    if (Metings.length === 0) {return;};
    if (Metings[0].aplayer && Metings[0].aplayer.on) {
      // improve the accessibility https://web.dev/button-name/
      document.querySelectorAll(".aplayer-icon-menu").forEach(e=>{
        e.setAttribute("aria-label","Aplayer Menu")
      })
      // message see: /layout/_plugins/message/script.ejs
      
        try {
          setTimeout(() => {
            Metings.forEach((item, index) => {
              const aplayerItem = item.aplayer; if(!aplayerItem) return;
              const rightAplayerCheck = 'true' === 'true'
                && item.meta.id === '993524571';
              if(rightAplayerCheck && typeof RightMenuAplayer !="undefined") RightMenuAplayer.checkAPlayer();
              if(aplayerItem.events.events.play.every(item => {return item.name !== 'messagePlay'})) {
                aplayerItem.on('play', function messagePlay() {
                  let index = aplayerItem.list.index;
                  let title = aplayerItem.list.audios[index].title;
                  let artist = aplayerItem.list.audios[index].artist;
                  setTimeout(() => {
                    VolantisApp.message('音乐通知', title + ' - ' + artist, {
                      icon: 'fa-solid fa-play',
                      transitionIn: 'flipInX',
                      transitionOut: 'flipOutX'
                    });
                  }, 100)
                });
              }
              if(aplayerItem.events.events.pause.every(item => {return item.name !== 'messagePause'})) {
                aplayerItem.on('pause', function messagePause() {
                  let index = aplayerItem.list.index;
                  let title = aplayerItem.list.audios[index].title;
                  let artist = aplayerItem.list.audios[index].artist;
                  setTimeout(() => {
                    // 歌曲播放结束也会触发 pause 事件，为了避免错误提示，等待一会儿
                    if(aplayerItem.paused) {
                      VolantisApp.message('音乐通知', title + ' - ' + artist, {
                        icon: 'fa-solid fa-pause',
                        transitionIn: 'flipInX',
                        transitionOut: 'flipOutX'
                      });
                    }
                  }, 100)
                });
              }
            });
          }, 500)
        } catch (error) { console.error(error); }
      
    }else{
      volantis.requestAnimationFrame(SetAPlayerPlugin)
    }
  }

  document.addEventListener("DOMContentLoaded", ()=>{
    SetAPlayerPlugin();
  });
  volantis.pjax.push(SetAPlayerPlugin);
</script>




      <script>
  volantis.layoutHelper("comments",`<div id="giscus_container"></div>`)

  volantis.giscus = {};

  function check_giscus() {
    if (volantis.dark.mode === "dark") {
      volantis.giscus.Theme = 'dark';
    } else {
      volantis.giscus.Theme = 'light';
    }

    return document.getElementById("giscus_container");
  }

  function pjax_giscus() {
    const HEAD = check_giscus();
    if (!HEAD) return;
    let cfg = Object.assign({"theme":{"light":"light","dark":"dark"},"repo":"MengFanjun020906/comments","repo-id":"R_kgDOIjrvJg","category":"Announcements","category-id":"DIC_kwDOIjrvJs4CS6YN","mapping":"pathname","reactions-enabled":"1","emit-metadata":"0","lang":"zh-CN"},pdata.commentConfig)
    const script = document.createElement('script');
    script.setAttribute('src', 'https://giscus.app/client.js');
    Object.keys(cfg).forEach(k=>{
      if (k != "theme") {
        script.setAttribute('data-'+k, cfg[k]);
      }
    })
    script.setAttribute('data-theme', volantis.giscus.Theme);
    script.setAttribute('crossorigin', "anonymous");
    HEAD.appendChild(script);
  }

  function dark_giscus() {
    const HEAD = check_giscus();
    if (!HEAD) return;

    const message = {
      setConfig: {
        theme: volantis.giscus.Theme
      }
    };
    const giscusIframe = document.querySelector('iframe.giscus-frame');
    giscusIframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
  }
  pjax_giscus();
  volantis.pjax.push(pjax_giscus);
  volantis.dark.push(dark_giscus);
</script>

    




  <script defer src="https://gcore.jsdelivr.net/gh/volantis-x/cdn-busuanzi@2.3/js/busuanzi.pure.mini.js" data-pjax></script>


<!-- optional -->

  <script>
  const SearchServiceDataPathRoot = ("/" || "/").endsWith("/") ?
    "/" || "/" :
    "//" || "/";
  const SearchServiceDataPath = SearchServiceDataPathRoot + "content.json";

  function loadSearchScript() {
    // see: layout/_partial/scripts/_ctrl/cdnCtrl.ejs
    return volantis.js("/js/search/hexo.js");
  }

  function loadSearchService() {
    loadSearchScript();
    document.querySelectorAll(".input.u-search-input").forEach((e) => {
      e.removeEventListener("focus", loadSearchService, false);
    });

    document.querySelectorAll(".u-search-form").forEach((e) => {
      e.addEventListener("submit", (event) => {
        event.preventDefault();
      }, false);
    });
  }

  // 打开并搜索 字符串 s
  function OpenSearch(s) {
    if (typeof SearchService === 'undefined')
      loadSearchScript().then(() => {
        SearchService.setQueryText(s);
        SearchService.search();
      });
    else {
      SearchService.setQueryText(s);
      SearchService.search();
    }
  }

  // 访问含有 ?s=xxx  的链接时打开搜索 // 与搜索引擎 structured data 相关: /scripts/helpers/structured-data/lib/config.js
  if (window.location.search && /^\?s=/g.test(window.location.search)) {
    let queryText = decodeURI(window.location.search)
      .replace(/\ /g, "-")
      .replace(/^\?s=/g, "");
    OpenSearch(queryText);
  }

  // 搜索输入框获取焦点时加载搜索
  document.querySelectorAll(".input.u-search-input").forEach((e) => {
    e.addEventListener("focus", loadSearchService, false);
  });
</script>







  <script>



  function pjax_highlightjs_copyCode(){
    if (!(document.querySelector(".highlight .code pre") ||
      document.querySelector(".article pre code"))) {
      return;
    }
    VolantisApp.utilCopyCode(".highlight .code pre, .article pre code")
  }
  volantis.requestAnimationFrame(pjax_highlightjs_copyCode)
  volantis.pjax.push(pjax_highlightjs_copyCode)

</script>










  <script>
  let imgs = ["https://mfjblog-pic.oss-cn-beijing.aliyuncs.com/img/1071826.jpg"];
  let index = 0;
  let IntervalParallax = null;

  function parallax(){
    let ParallaxWindow = document.querySelector("#parallax-window");
    
      ParallaxWindow = document.querySelector("html");
    
    Parallax.window = ParallaxWindow;
    Parallax.options.fade = 1500;
    Parallax.cache = 1;
    next_parallax();
    Parallax.init();
    if (imgs.length>1) {
      IntervalParallax = setInterval(function () {
        next_parallax();
      }, '10000');
    }
  }

  function next_parallax() {
    if (typeof Parallax == "undefined") {
      return
    }
    
    if (imgs.length>=1) {
      Parallax.options.src = imgs[index % imgs.length];
      Parallax.start();
      index++;
      if (Parallax.cache) {
        fetch(imgs[index % imgs.length] +"?t=" + new Date().getTime());
        if (index == imgs.length) {
          Parallax.cache = 0;
        }
      }
    }
  }
  var runningOnBrowser = typeof window !== "undefined";
  var isBot = runningOnBrowser && !("onscroll" in window) || typeof navigator !== "undefined" && /(gle|ing|ro|msn)bot|crawl|spider|yand|duckgo/i.test(navigator.userAgent);
  if (!isBot) {
    volantis.js('/js/plugins/parallax.js').then(()=>{
      parallax()
    })
    volantis.pjax.send(()=>{
      clearInterval(IntervalParallax)
    },"clearIntervalParallax");
    volantis.pjax.push(parallax);
  }
</script>




  <script>
  function load_swiper() {
    if (!document.querySelectorAll(".swiper-container")[0]) return;
    volantis.css("https://unpkg.com/volantis-static@0.0.1654736714924/libs/swiper/swiper-bundle.min.css");
    volantis.js("https://unpkg.com/volantis-static@0.0.1654736714924/libs/swiper/swiper-bundle.min.js").then(() => {
      pjax_swiper();
    });
  }

  load_swiper();

  function pjax_swiper() {
    volantis.swiper = new Swiper('.swiper-container', {
      slidesPerView: 'auto',
      spaceBetween: 8,
      centeredSlides: true,
      loop: true,
      pagination: {
        el: '.swiper-pagination',
        clickable: true,
      },
      navigation: {
        nextEl: '.swiper-button-next',
        prevEl: '.swiper-button-prev',
      },
    });
  }

  volantis.pjax.push(() => {
    if (!document.querySelectorAll(".swiper-container")[0]) return;
    if (typeof volantis.swiper === "undefined") {
      load_swiper();
    } else {
      pjax_swiper();
    }
  });
</script>


<!-- pjax 标签必须存在于所有页面 否则 pjax error -->
<pjax>

        <script>
  // https://github.com/theme-next/hexo-theme-next/blob/master/layout/_third-party/math/mathjax.swig
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = "https://unpkg.com/volantis-static@0.0.1654736714924/libs/mathjax/es5/tex-mml-chtml.js";
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    // 文章章节标题不能为 “MathJax” ，否则会报错。
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typesetPromise();
  }
</script>



</pjax>

<script>
  function listennSidebarTOC() {
    const navItems = document.querySelectorAll(".toc li");
    if (!navItems.length) return;
    let targets = []
    const sections = [...navItems].map((element) => {
      const link = element.querySelector(".toc-link");
      const target = document.getElementById(
        decodeURI(link.getAttribute("href")).replace("#", "")
      );
      targets.push(target)
      // 解除 a 标签 href 的 锚点定位, a 标签 href 的 锚点定位 会随机启用?? 产生错位???
      link.setAttribute("onclick","return false;")
      link.setAttribute("toc-action","toc-"+decodeURI(link.getAttribute("href")).replace("#", ""))
      link.setAttribute("href","/")
      // 配置 点击 触发新的锚点定位
      link.addEventListener("click", (event) => {
        event.preventDefault();
        // 这里的 addTop 是通过错位使得 toc 自动展开.
        volantis.scroll.to(target,{addTop: 5, observer:true})
        // Anchor id
        history.pushState(null, document.title, "#" + target.id);
      });
      return target;
    });

    function activateNavByIndex(target) {
      if (target.classList.contains("active-current")) return;

      document.querySelectorAll(".toc .active").forEach((element) => {
        element.classList.remove("active", "active-current");
      });
      target.classList.add("active", "active-current");
      let parent = target.parentNode;
      while (!parent.matches(".toc")) {
        if (parent.matches("li")) parent.classList.add("active");
        parent = parent.parentNode;
      }
    }

    // 方案一：
    volantis.activateNavIndex=0
    activateNavByIndex(navItems[volantis.activateNavIndex])
    volantis.scroll.push(()=>{
      if (targets[0].getBoundingClientRect().top >= 0) {
        volantis.activateNavIndex = 0
      }else if (targets[targets.length-1].getBoundingClientRect().top < 0) {
        volantis.activateNavIndex = targets.length-1
      } else {
        for (let index = 0; index < targets.length; index++) {
          const target0 = targets[index];
          const target1 = targets[(index+1)%targets.length];
          if (target0.getBoundingClientRect().top < 0&&target1.getBoundingClientRect().top >= 0) {
            volantis.activateNavIndex=index
            break;
          }
        }
      }
      activateNavByIndex(navItems[volantis.activateNavIndex])
    })

    // 方案二：
    // IntersectionObserver 不是完美精确到像素级别 也不是低延时性的
    // function findIndex(entries) {
    //   let index = 0;
    //   let entry = entries[index];
    //   if (entry.boundingClientRect.top > 0) {
    //     index = sections.indexOf(entry.target);
    //     return index === 0 ? 0 : index - 1;
    //   }
    //   for (; index < entries.length; index++) {
    //     if (entries[index].boundingClientRect.top <= 0) {
    //       entry = entries[index];
    //     } else {
    //       return sections.indexOf(entry.target);
    //     }
    //   }
    //   return sections.indexOf(entry.target);
    // }
    // function createIntersectionObserver(marginTop) {
    //   marginTop = Math.floor(marginTop + 10000);
    //   let intersectionObserver = new IntersectionObserver(
    //     (entries, observe) => {
    //       let scrollHeight = document.documentElement.scrollHeight;
    //       if (scrollHeight > marginTop) {
    //         observe.disconnect();
    //         createIntersectionObserver(scrollHeight);
    //         return;
    //       }
    //       let index = findIndex(entries);
    //       activateNavByIndex(navItems[index]);
    //     }, {
    //       rootMargin: marginTop + "px 0px -100% 0px",
    //       threshold: 0,
    //     }
    //   );
    //   sections.forEach((element) => {
    //     element && intersectionObserver.observe(element);
    //   });
    // }
    // createIntersectionObserver(document.documentElement.scrollHeight);
  }

  document.addEventListener("DOMContentLoaded", ()=>{
    volantis.requestAnimationFrame(listennSidebarTOC)
  });
  document.addEventListener("pjax:success", ()=>{
    volantis.requestAnimationFrame(listennSidebarTOC)
  });
</script>



<script>
  document.onreadystatechange = function () {
    if (document.readyState == 'complete') {
      // 页面加载完毕 样式加载失败，或是当前网速慢，或是开启了省流模式
      const { saveData, effectiveType } = navigator.connection || navigator.mozConnection || navigator.webkitConnection || {}
      if (getComputedStyle(document.querySelector("#safearea"), null)["display"] == "none" || saveData || /2g/.test(effectiveType)) {
        document.querySelectorAll(".reveal").forEach(function (e) {
          e.style["opacity"] = "1";
        });
        document.querySelector("#safearea").style["display"] = "block";
      }
    }
  }
</script>


  <script type="application/ld+json">[{"@context":"http://schema.org","@type":"Organization","name":"MengFanjun的博客","url":"https://mengfanjun020906.github.io/","logo":{"@type":"ImageObject","url":"https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/favicon/android-chrome-192x192.png","width":192,"height":192}},{"@context":"http://schema.org","@type":"Person","name":"MengFanjun","image":{"@type":"ImageObject","url":"https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/favicon/android-chrome-192x192.png"},"url":"https://mengfanjun020906.github.io/","sameAs":["https://github.com/volantis-x"],"description":"20级通信工程大学生的个人博客"},{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"https://mengfanjun020906.github.io/","name":"MengFanjun的博客"}},{"@type":"ListItem","position":3,"item":{"@id":"https://mengfanjun020906.github.io/2025/10/02/Stanford CS336 assignment1（上）/","name":"Stanford CS336 assignment1（上）"}}]},{"@context":"http://schema.org","@type":"WebSite","name":"MengFanjun的博客","url":"https://mengfanjun020906.github.io/","keywords":null,"description":"20级通信工程大学生的个人博客","author":{"@type":"Person","name":"MengFanjun","image":{"@type":"ImageObject","url":"https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/favicon/android-chrome-192x192.png"},"url":"https://mengfanjun020906.github.io/","description":"20级通信工程大学生的个人博客"},"publisher":{"@type":"Organization","name":"MengFanjun的博客","url":"https://mengfanjun020906.github.io/","logo":{"@type":"ImageObject","url":"https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/favicon/android-chrome-192x192.png","width":192,"height":192}},"potentialAction":{"@type":"SearchAction","name":"Site Search","target":{"@type":"EntryPoint","urlTemplate":"https://mengfanjun020906.github.io?s={search_term_string}"},"query-input":"required name=search_term_string"}},{"@context":"http://schema.org","@type":"BlogPosting","headline":"Stanford CS336 assignment1（上）","description":"20级通信工程大学生的个人博客","inLanguage":"en","mainEntityOfPage":{"@type":"WebPage","@id":"https://mengfanjun020906.github.io/2025/10/02/Stanford%20CS336%20assignment1%EF%BC%88%E4%B8%8A%EF%BC%89/"},"author":{"@type":"Person","name":"MengFanjun","image":{"@type":"ImageObject","url":"https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/favicon/android-chrome-192x192.png"},"url":"https://mengfanjun020906.github.io/"},"publisher":{"@type":"Organization","name":"MengFanjun的博客","logo":{"@type":"ImageObject","url":"https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/favicon/android-chrome-192x192.png","width":192,"height":192}},"url":"https://mengfanjun020906.github.io/2025/10/02/Stanford%20CS336%20assignment1%EF%BC%88%E4%B8%8A%EF%BC%89/","wordCount":0,"datePublished":"2025-10-02T03:27:32.000Z","dateModified":"2025-12-12T14:25:39.018Z","keywords":"学习,大模型","image":{"@type":"ImageObject","url":"https://unpkg.com/volantis-static@0.0.1654736714924/media/org.volantis/blog/favicon/android-chrome-192x192.png","width":192,"height":192}}]</script>



      
        <!--
  pjax重载区域接口：
  1.  <pjax></pjax> 标签 pjax 标签必须存在于所有页面 否则 pjax error
  2.  script[data-pjax]
  3.  .pjax-reload script
  4.  .pjax
-->



<script src="https://unpkg.com/volantis-static@0.0.1654736714924/libs/pjax/pjax.min.js"></script>


<script>
    var pjax;
    document.addEventListener('DOMContentLoaded', function () {
      pjax = new Pjax({
        elements: 'a[href]:not([href^="#"]):not([href="javascript:void(0)"]):not([pjax-fancybox]):not([onclick="return false;"]):not([onclick="return!1"]):not([target="_blank"]):not([target="view_window"]):not([href$=".xml"])',
        selectors: [
          "head title",
          "head meta[name=keywords]",
          "head meta[name=description]",
          
          "#l_main",
          "#pjax-header-nav-list",
          ".pjax",
          "pjax", // <pjax></pjax> 标签
          "script[data-pjax], .pjax-reload script" // script标签添加data-pjax 或 script标签外层添加.pjax-reload 的script代码段重载
        ],
        cacheBust: false,   // url 地址追加时间戳，用以避免浏览器缓存
        timeout: 5000,
        
      });
    });

    document.addEventListener('pjax:send', function (e) {
      //window.stop(); // 相当于点击了浏览器的停止按钮

      try {
        var currentUrl = window.location.pathname;
        var targetUrl = e.triggerElement.href;
        var banUrl = [""];
        if (banUrl[0] != "") {
          banUrl.forEach(item => {
            if(currentUrl.indexOf(item) != -1 || targetUrl.indexOf(item) != -1) {
              window.location.href = targetUrl;
            }
          });
        }
      } catch (error) {}

      // 使用 volantis.pjax.send 方法传入pjax:send回调函数 参见layout/_partial/scripts/global.ejs
      volantis.pjax.method.send.start();
    });

    document.addEventListener('pjax:complete', function () {
      // 使用 volantis.pjax.push 方法传入重载函数 参见layout/_partial/scripts/global.ejs
      volantis.pjax.method.complete.start();
    });

    document.addEventListener('pjax:error', function (e) {
      if(volantis.debug) {
        console.error(e);
        console.log('pjax error: \n' + JSON.stringify(e));
      }else{
        // 使用 volantis.pjax.error 方法传入pjax:error回调函数 参见layout/_partial/scripts/global.ejs
        volantis.pjax.method.error.start();
        window.location.href = e.triggerElement.href;
      }
    });
</script>

      
    </div>
    <!-- import body_end begin-->
    <!-- import body_end end-->
    <!-- Custom Files bodyEnd begin-->
    
    <!-- Custom Files bodyEnd end-->
  </body>
</html>
